# R060: Consolidação dos Processadores de Conteúdo

## Descrição

Unificar e padronizar os processadores de conteúdo em todo o framework, eliminando implementações redundantes e estabelecendo uma interface consistente para processamento de diferentes tipos de conteúdo. O sistema atual possui múltiplas implementações de processamento espalhadas em diferentes módulos.

## Dependências

- R024: Consolidação do Sistema de Observabilidade
- R059: Padronização de Protocolos e Interfaces

## Estado Atual

Atualmente, o processamento de conteúdo está distribuído em vários módulos:

1. Em `core/processors/text.py`:
```python
class TextProcessor:
    """Process text content."""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        
    async def process(
        self,
        content: str,
        **options: Any
    ) -> ProcessingResult:
        """Process text content."""
        # Implementation
        pass
```

2. Em `core/processors/code.py`:
```python
class CodeProcessor:
    """Process code content."""
    
    def __init__(self, language: str):
        self.language = language
        
    async def process(
        self,
        content: str,
        **options: Any
    ) -> ProcessingResult:
        """Process code content."""
        # Implementation
        pass
```

## Plano de Implementação

1. Criar sistema base de processamento:

```python
from abc import ABC, abstractmethod
from typing import Any, Dict, Generic, List, Optional, TypeVar
from dataclasses import dataclass
from datetime import datetime

T = TypeVar("T")
R = TypeVar("R")

@dataclass
class ProcessingContext:
    """Context for content processing."""
    content_type: str
    metadata: Dict[str, Any]
    options: Dict[str, Any]
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class ProcessingResult(Generic[R]):
    """Result of content processing."""
    content: R
    metadata: Dict[str, Any]
    errors: List[str]
    warnings: List[str]
    processing_time: float

class ContentProcessor(ABC, Generic[T, R]):
    """Base class for content processors."""
    
    @abstractmethod
    async def process(
        self,
        content: T,
        context: ProcessingContext
    ) -> ProcessingResult[R]:
        """Process content."""
        pass
    
    @abstractmethod
    async def validate(
        self,
        content: T,
        context: ProcessingContext
    ) -> List[str]:
        """Validate content."""
        pass
    
    @abstractmethod
    async def cleanup(self) -> None:
        """Clean up resources."""
        pass
```

2. Implementar sistema de registro de processadores:

```python
class ProcessorRegistry:
    """Registry for content processors."""
    
    def __init__(self):
        self._processors: Dict[str, Dict[str, ContentProcessor]] = {}
        self._metrics = MetricsManager.get_instance()
        
    def register(
        self,
        content_type: str,
        version: str,
        processor: ContentProcessor
    ) -> None:
        """Register a content processor."""
        if content_type not in self._processors:
            self._processors[content_type] = {}
        self._processors[content_type][version] = processor
        
    async def get_processor(
        self,
        content_type: str,
        version: Optional[str] = None
    ) -> ContentProcessor:
        """Get content processor."""
        if content_type not in self._processors:
            raise ValueError(f"Processor not found: {content_type}")
            
        processors = self._processors[content_type]
        if not version:
            # Get latest version
            version = max(processors.keys())
            
        if version not in processors:
            raise ValueError(f"Version not found: {version}")
            
        return processors[version]
```

3. Implementar processadores específicos:

```python
class TextProcessor(ContentProcessor[str, str]):
    """Process text content."""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self._metrics = MetricsManager.get_instance()
        
    async def process(
        self,
        content: str,
        context: ProcessingContext
    ) -> ProcessingResult[str]:
        start_time = time.time()
        
        try:
            # Process text content
            processed = self._process_text(content, context)
            
            return ProcessingResult(
                content=processed,
                metadata={"config": self.config},
                errors=[],
                warnings=[],
                processing_time=time.time() - start_time
            )
            
        except Exception as e:
            return ProcessingResult(
                content=content,
                metadata={"error": str(e)},
                errors=[str(e)],
                warnings=[],
                processing_time=time.time() - start_time
            )
            
    async def validate(
        self,
        content: str,
        context: ProcessingContext
    ) -> List[str]:
        errors = []
        
        if not content:
            errors.append("Empty content")
            
        if len(content) > self.config.get("max_length", 1000000):
            errors.append("Content too long")
            
        return errors
        
    async def cleanup(self) -> None:
        """Clean up resources."""
        pass
        
    def _process_text(
        self,
        content: str,
        context: ProcessingContext
    ) -> str:
        # Implementation
        return content

class CodeProcessor(ContentProcessor[str, str]):
    """Process code content."""
    
    def __init__(self, language: str):
        self.language = language
        self._metrics = MetricsManager.get_instance()
        
    async def process(
        self,
        content: str,
        context: ProcessingContext
    ) -> ProcessingResult[str]:
        start_time = time.time()
        
        try:
            # Process code content
            processed = self._process_code(content, context)
            
            return ProcessingResult(
                content=processed,
                metadata={"language": self.language},
                errors=[],
                warnings=[],
                processing_time=time.time() - start_time
            )
            
        except Exception as e:
            return ProcessingResult(
                content=content,
                metadata={"error": str(e)},
                errors=[str(e)],
                warnings=[],
                processing_time=time.time() - start_time
            )
            
    async def validate(
        self,
        content: str,
        context: ProcessingContext
    ) -> List[str]:
        errors = []
        
        if not content:
            errors.append("Empty content")
            
        if not self._is_valid_syntax(content):
            errors.append(f"Invalid {self.language} syntax")
            
        return errors
        
    async def cleanup(self) -> None:
        """Clean up resources."""
        pass
        
    def _process_code(
        self,
        content: str,
        context: ProcessingContext
    ) -> str:
        # Implementation
        return content
        
    def _is_valid_syntax(self, content: str) -> bool:
        # Implementation
        return True
```

4. Implementar sistema de monitoramento:

```python
class ProcessorMonitor:
    """Monitor for content processors."""
    
    def __init__(self):
        self._metrics = MetricsManager.get_instance()
        
    async def record_processing(
        self,
        processor: str,
        content_type: str,
        success: bool = True,
        processing_time: float = 0.0,
        **labels: str
    ) -> None:
        """Record processing operation."""
        self._metrics.counter(
            "processor_operations",
            1,
            processor=processor,
            content_type=content_type,
            success=str(success).lower(),
            **labels
        )
        
        self._metrics.histogram(
            "processor_time",
            processing_time,
            processor=processor,
            content_type=content_type,
            **labels
        )
```

5. Migrar implementações existentes:
   - Atualizar `core/processors/text.py`
   - Atualizar `core/processors/code.py`
   - Criar novos processadores conforme necessário

## Validação

```python
async def test_processor_system():
    # Setup
    registry = ProcessorRegistry()
    monitor = ProcessorMonitor()
    
    # Register processors
    text_processor = TextProcessor({"max_length": 1000})
    code_processor = CodeProcessor("python")
    
    registry.register("text", "1.0.0", text_processor)
    registry.register("code", "1.0.0", code_processor)
    
    # Test text processing
    context = ProcessingContext(
        content_type="text",
        metadata={},
        options={}
    )
    
    result = await text_processor.process(
        "Sample text",
        context
    )
    
    assert not result.errors
    assert result.content == "Sample text"
    
    # Test code processing
    context = ProcessingContext(
        content_type="code",
        metadata={"language": "python"},
        options={}
    )
    
    result = await code_processor.process(
        "def test(): pass",
        context
    )
    
    assert not result.errors
    assert "def test():" in result.content
    
    # Test monitoring
    await monitor.record_processing(
        "text",
        "text/plain",
        True,
        0.1
    )
```

## Plano de Rollback

1. Manter implementações antigas em módulos separados com sufixo `_legacy`
2. Implementar função de migração reversa:
```python
async def rollback_processor_system():
    # Restore legacy implementations
    shutil.copy("core/processors/text_legacy.py", "core/processors/text.py")
    shutil.copy("core/processors/code_legacy.py", "core/processors/code.py")
    
    # Cleanup new implementations
    os.remove("core/processors/base.py")
    os.remove("core/processors/registry.py")
    os.remove("core/processors/monitor.py")
```

## Métricas de Sucesso

1. **Padronização**:
   - Zero duplicação de processadores
   - Interface consistente
   - Implementações unificadas

2. **Qualidade**:
   - 100% de cobertura de testes
   - Zero erros de processamento não tratados
   - Documentação completa

3. **Performance**:
   - Latência < 100ms para processamento de texto
   - Latência < 500ms para processamento de código
   - Uso eficiente de recursos

## Atualizações de Progresso

- [x] Criação do requisito (2024-02-22)
- [ ] Implementação do sistema base de processadores
- [ ] Implementação do registro de processadores
- [ ] Implementação dos processadores específicos
- [ ] Implementação do sistema de monitoramento
- [ ] Migração das implementações existentes
- [ ] Testes de integração
- [ ] Documentação atualizada
- [ ] Revisão de código
- [ ] Deploy em produção 