# R049: Padronização do Sistema de Métricas

## Descrição

Padronizar o sistema de métricas para garantir consistência na coleta, agregação e exportação de métricas em todo o framework. O sistema atual apresenta diferentes implementações de métricas em diferentes módulos, dificultando a observabilidade e o monitoramento do sistema.

## Dependências

- R024: Consolidação do Sistema de Observabilidade
- R046: Padronização do Sistema de Registro e Logging

## Estado Atual

Atualmente, o sistema de métricas está disperso em vários módulos com diferentes implementações:

1. Em `core/config/manager.py`:
```python
class ConfigurationManager(Generic[T]):
    def __init__(self, config_class: Type[T]) -> None:
        self._metrics = MetricsManager.get_instance()
        self._file_reads: Optional[Counter] = None
        self._file_read_errors: Optional[Counter] = None
        self._validation_errors: Optional[Counter] = None
```

2. Em `memory/providers/local.py`:
```python
class LocalProvider(MemoryProvider):
    async def keys(self, pattern: Optional[str] = None, **kwargs: Any) -> List[str]:
        try:
            async with self._lock:
                if pattern:
                    return [key for key in self.entries 
                           if key.startswith(pattern) and 
                           not (self.entries[key].expires_at and 
                                self.entries[key].expires_at <= datetime.now())]
        except Exception as e:
            raise MemoryError(
                "Failed to get keys",
                provider="local",
                details={"error": str(e)},
            )
```

3. Em `core/client.py`:
```python
class PepperpyClient(PepperpyClientProtocol, Lifecycle):
    async def remove_agent(self, agent_id: UUID) -> None:
        try:
            if hasattr(agent, "cleanup"):
                await agent.cleanup()
            del self._agents[agent_id]
            self._updated_at = time.time()
```

## Plano de Implementação

1. Criar uma interface unificada para métricas:

```python
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional, Union
from enum import Enum
from dataclasses import dataclass
import time

class MetricType(Enum):
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    SUMMARY = "summary"

@dataclass
class MetricDefinition:
    name: str
    type: MetricType
    description: str
    labels: List[str]
    unit: Optional[str] = None

class MetricsCollector(ABC):
    @abstractmethod
    def counter(self, name: str, description: str, labels: List[str] = None) -> None:
        """Create a counter metric."""
        pass
    
    @abstractmethod
    def gauge(self, name: str, description: str, labels: List[str] = None) -> None:
        """Create a gauge metric."""
        pass
    
    @abstractmethod
    def histogram(self, name: str, description: str, buckets: List[float], 
                 labels: List[str] = None) -> None:
        """Create a histogram metric."""
        pass
    
    @abstractmethod
    def summary(self, name: str, description: str, quantiles: List[float], 
                labels: List[str] = None) -> None:
        """Create a summary metric."""
        pass
```

2. Implementar o coletor de métricas padrão:

```python
class StandardMetricsCollector(MetricsCollector):
    def __init__(self):
        self._metrics: Dict[str, MetricDefinition] = {}
        self._values: Dict[str, Dict[str, float]] = {}
        self._start_time = time.time()
        
    def counter(self, name: str, description: str, labels: List[str] = None) -> None:
        self._metrics[name] = MetricDefinition(
            name=name,
            type=MetricType.COUNTER,
            description=description,
            labels=labels or []
        )
        self._values[name] = {}
        
    def increment(self, name: str, value: float = 1.0, **labels: str) -> None:
        if name not in self._metrics:
            raise ValueError(f"Metric {name} not registered")
            
        label_key = self._label_key(**labels)
        if label_key not in self._values[name]:
            self._values[name][label_key] = 0
        self._values[name][label_key] += value
        
    def _label_key(self, **labels: str) -> str:
        return ",".join(f"{k}={v}" for k, v in sorted(labels.items()))
```

3. Criar decoradores para medição automática:

```python
def measure_time(metric_name: str, **labels: str):
    def decorator(func):
        @wraps(func)
        async def wrapper(self, *args, **kwargs):
            start_time = time.time()
            try:
                result = await func(self, *args, **kwargs)
                duration = time.time() - start_time
                self._metrics.histogram(
                    name=metric_name,
                    value=duration,
                    **labels
                )
                return result
            except Exception as e:
                self._metrics.counter(
                    name=f"{metric_name}_errors",
                    value=1,
                    error=e.__class__.__name__,
                    **labels
                )
                raise
        return wrapper
    return decorator

def track_usage(metric_name: str, **labels: str):
    def decorator(func):
        @wraps(func)
        async def wrapper(self, *args, **kwargs):
            self._metrics.counter(
                name=metric_name,
                value=1,
                **labels
            )
            return await func(self, *args, **kwargs)
        return wrapper
    return decorator
```

4. Implementar exportação de métricas:

```python
class MetricsExporter:
    def __init__(self, collector: MetricsCollector):
        self._collector = collector
        
    def export_prometheus(self) -> str:
        """Export metrics in Prometheus format."""
        lines = []
        for name, metric in self._collector._metrics.items():
            # Add metric metadata
            lines.append(f"# HELP {name} {metric.description}")
            lines.append(f"# TYPE {name} {metric.type.value}")
            
            # Add metric values
            for label_key, value in self._collector._values[name].items():
                if label_key:
                    labels = "{" + label_key + "}"
                    lines.append(f"{name}{labels} {value}")
                else:
                    lines.append(f"{name} {value}")
                    
        return "\n".join(lines)
        
    def export_json(self) -> Dict[str, Any]:
        """Export metrics in JSON format."""
        return {
            "metrics": {
                name: {
                    "type": metric.type.value,
                    "description": metric.description,
                    "values": self._collector._values[name]
                }
                for name, metric in self._collector._metrics.items()
            }
        }
```

5. Migrar implementações existentes:
   - Atualizar `core/config/manager.py`
   - Refatorar `memory/providers/local.py`
   - Modificar `core/client.py`

## Validação

```python
async def test_metrics_system():
    # Setup
    collector = StandardMetricsCollector()
    
    # Test counter
    collector.counter("test_counter", "Test counter")
    collector.increment("test_counter", 1, label="test")
    assert collector._values["test_counter"]["label=test"] == 1
    
    # Test decorator
    class TestService:
        def __init__(self):
            self._metrics = collector
            
        @measure_time("test_operation")
        async def slow_operation(self):
            await asyncio.sleep(0.1)
            return "done"
            
        @track_usage("test_usage")
        async def tracked_operation(self):
            return "tracked"
    
    service = TestService()
    await service.slow_operation()
    await service.tracked_operation()
    
    # Test export
    exporter = MetricsExporter(collector)
    prometheus_output = exporter.export_prometheus()
    assert "test_counter" in prometheus_output
    assert "test_operation" in prometheus_output
    assert "test_usage" in prometheus_output
```

## Plano de Rollback

1. Manter implementações antigas em módulos separados com sufixo `_legacy`
2. Implementar função de migração reversa:
```python
async def rollback_metrics_system():
    # Restore legacy implementations
    shutil.copy("core/metrics_legacy.py", "core/metrics.py")
    
    # Cleanup new implementations
    os.remove("core/metrics_collector.py")
    os.remove("core/metrics_exporter.py")
```

## Métricas de Sucesso

1. **Padronização**:
   - 100% dos módulos usando o novo sistema de métricas
   - Zero implementações customizadas de métricas
   - Formato consistente de exportação

2. **Observabilidade**:
   - Cobertura de métricas > 95%
   - Latência de coleta < 1ms
   - Taxa de amostragem > 99%

3. **Desempenho**:
   - Overhead de métricas < 0.1ms por operação
   - Uso de memória < 50MB
   - Tempo de exportação < 100ms

## Atualizações de Progresso

- [x] Criação do requisito (2024-02-22)
- [ ] Implementação da interface MetricsCollector
- [ ] Implementação do StandardMetricsCollector
- [ ] Implementação dos decoradores de métricas
- [ ] Implementação do sistema de exportação
- [ ] Migração das implementações existentes
- [ ] Testes de integração
- [ ] Documentação atualizada
- [ ] Revisão de código
- [ ] Deploy em produção 