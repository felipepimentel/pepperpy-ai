---
title: PepperPy Workflow System
description: Apply this rule when implementing, extending, or discussing any Workflow system components in the PepperPy framework
globs:
  - "pepperpy/workflow/**/*.py"
priority: 700
alwaysApply: false
---

# PepperPy Workflow System

## Overview

The Workflow module in PepperPy provides a flexible system for defining, composing, and executing complex workflows. This rule provides guidelines for implementing and extending the workflow system.

## Architecture

The Workflow system is organized into these key components:

```
pepperpy/workflow/
├── __init__.py               # Public API exports
├── provider.py               # Workflow provider interface
├── models.py                 # Core domain models
├── exceptions.py             # Domain-specific exceptions
├── utils.py                  # Utility functions
│
├── engine/                   # Workflow execution engine
│   ├── __init__.py
│   ├── executor.py           # Workflow executor
│   └── scheduler.py          # Task scheduler
│
├── definition/               # Workflow definition
│   ├── __init__.py
│   ├── task.py               # Task definitions
│   ├── condition.py          # Conditional execution
│   └── workflow.py           # Workflow definitions
│
└── providers/                # Workflow implementations
    ├── __init__.py
    ├── local.py              # Local workflow implementation
    ├── distributed.py        # Distributed workflow implementation
    └── async.py              # Async workflow implementation
```

## Core Models

The Workflow system is built around these core domain models:

```python
class Task:
    """Represents a single unit of work in a workflow."""
    id: str
    name: str
    description: Optional[str]
    handler: Callable
    inputs: dict[str, Any]
    outputs: dict[str, Any]
    
class Workflow:
    """Represents a workflow definition."""
    id: str
    name: str
    description: Optional[str]
    version: str
    tasks: list[Task]
    edges: list[Edge]
    
class Edge:
    """Represents a connection between tasks."""
    source_task_id: str
    target_task_id: str
    condition: Optional[Condition]
    
class WorkflowExecution:
    """Represents an execution instance of a workflow."""
    id: str
    workflow_id: str
    status: WorkflowStatus
    start_time: datetime
    end_time: Optional[datetime]
    task_executions: list[TaskExecution]
```

## Provider Interfaces

### Workflow Provider

The main Workflow provider interface:

```python
class WorkflowProvider(BaseProvider):
    """Provider interface for workflow functionality."""
    
    async def register_workflow(self, workflow: Workflow) -> str:
        """Register a workflow definition."""
        ...
        
    async def execute_workflow(
        self, 
        workflow_id: str,
        inputs: dict[str, Any] = None
    ) -> WorkflowExecution:
        """Execute a workflow with the given inputs."""
        ...
        
    async def get_execution(self, execution_id: str) -> WorkflowExecution:
        """Get a workflow execution by ID."""
        ...
        
    async def cancel_execution(self, execution_id: str) -> None:
        """Cancel a workflow execution."""
        ...
```

## Implementation Patterns

### Task Definition

Tasks should be defined using the task builder pattern:

```python
# Define a task using the builder pattern
task = (
    Task.builder()
    .with_id("extract_entities")
    .with_name("Extract Entities")
    .with_description("Extract named entities from text")
    .with_handler(extract_entities_handler)
    .with_input("text", str)
    .with_output("entities", list[Entity])
    .build()
)

# Or using the functional approach
@task(
    id="extract_entities",
    name="Extract Entities",
    description="Extract named entities from text",
    inputs={"text": str},
    outputs={"entities": list[Entity]}
)
async def extract_entities(text: str) -> list[Entity]:
    # Implementation...
    return entities
```

### Workflow Definition

Workflows should be defined using the workflow builder pattern:

```python
# Define a workflow using the builder pattern
workflow = (
    Workflow.builder()
    .with_id("text_processing")
    .with_name("Text Processing")
    .with_description("Process text to extract insights")
    .with_version("1.0.0")
    .with_task(extract_entities_task)
    .with_task(classify_text_task)
    .with_task(generate_summary_task)
    .with_edge(
        source_task_id="extract_entities",
        target_task_id="classify_text"
    )
    .with_edge(
        source_task_id="classify_text",
        target_task_id="generate_summary"
    )
    .build()
)

# Or using the declarative approach
workflow = Workflow(
    id="text_processing",
    name="Text Processing",
    description="Process text to extract insights",
    version="1.0.0",
    tasks=[
        extract_entities_task,
        classify_text_task,
        generate_summary_task,
    ],
    edges=[
        Edge(source_task_id="extract_entities", target_task_id="classify_text"),
        Edge(source_task_id="classify_text", target_task_id="generate_summary"),
    ]
)
```

### Workflow Execution

To execute a workflow:

```python
# Register workflow
workflow_id = await workflow_provider.register_workflow(workflow)

# Execute workflow
execution = await workflow_provider.execute_workflow(
    workflow_id=workflow_id,
    inputs={"text": "Sample text to process"}
)

# Check execution status
execution = await workflow_provider.get_execution(execution.id)
if execution.status == WorkflowStatus.COMPLETED:
    # Process results
    pass
```

## Extension Guidelines

### Adding a New Task Handler

To add a new task handler:

1. Define the handler function:
   ```python
   async def my_custom_handler(input1: str, input2: int) -> dict[str, Any]:
       """Custom task handler."""
       # Implementation details...
       return {"result": result, "metadata": metadata}
   ```

2. Register it with the task system:
   ```python
   @task(
       id="my_custom_task",
       name="My Custom Task",
       inputs={"input1": str, "input2": int},
       outputs={"result": Any, "metadata": dict}
   )
   async def my_custom_task(input1: str, input2: int) -> dict[str, Any]:
       # Implementation that uses my_custom_handler
       return await my_custom_handler(input1, input2)
   ```

### Adding a New Workflow Provider

To add a new workflow provider:

1. Create a new file in `providers/` (e.g., `airflow.py`)
2. Implement the `WorkflowProvider` interface
3. Register it in the provider registry

```python
class AirflowWorkflowProvider(WorkflowProvider):
    """Airflow implementation of WorkflowProvider."""
    
    def __init__(self, airflow_endpoint: str, airflow_api_key: str):
        self.client = AirflowClient(airflow_endpoint, airflow_api_key)
    
    async def register_workflow(self, workflow: Workflow) -> str:
        """Register a workflow with Airflow."""
        # Convert PepperPy workflow to Airflow DAG
        dag = self._convert_to_dag(workflow)
        
        # Register DAG with Airflow
        response = await self.client.create_dag(dag)
        
        return response["dag_id"]
    
    async def execute_workflow(
        self, 
        workflow_id: str,
        inputs: dict[str, Any] = None
    ) -> WorkflowExecution:
        """Execute a workflow with Airflow."""
        # Implementation details...
```

## Configuration Patterns

The Workflow system uses a configuration pattern for customizing behavior:

```python
class WorkflowConfig(BaseSettings):
    """Configuration for the Workflow system."""
    
    # Execution settings
    max_retries: int = 3
    retry_delay: int = 5  # seconds
    timeout: int = 3600   # seconds
    
    # Engine settings
    parallel_tasks: int = 4
    execution_mode: str = "async"  # "async" or "sync"
    
    # Provider settings
    provider_type: str = "local"  # "local", "distributed", etc.
```

## Error Handling

Workflow-specific error handling should follow these patterns:

```python
try:
    execution = await workflow_provider.execute_workflow(workflow_id, inputs)
    # Process execution...
except WorkflowNotFoundError as e:
    # Handle workflow not found
    logger.error(f"Workflow not found: {e}")
    raise
except TaskExecutionError as e:
    # Handle task execution error
    logger.error(f"Task execution failed: {e}")
    task_id = e.task_id
    task_status = e.status
    # Perform recovery or logging...
except WorkflowTimeoutError as e:
    # Handle timeout
    logger.error(f"Workflow execution timed out: {e}")
    # Cleanup resources...
```

## Testing Guidelines

When testing Workflow components:

1. Use mock task handlers for testing workflows
2. Test workflow definitions without execution
3. Test error handling and edge cases
4. Validate workflow execution with simple workflows
5. Use integration tests for provider implementations

## Best Practices

1. **Idempotent Tasks**: Design tasks to be idempotent (can be safely retried)
2. **Task Granularity**: Keep tasks focused on a single responsibility
3. **Error Handling**: Implement proper error handling at both task and workflow levels
4. **Input Validation**: Validate all inputs at task boundaries
5. **State Management**: Avoid storing state in tasks; pass all state through inputs and outputs
6. **Monitoring**: Implement logging and monitoring in all workflows
7. **Versioning**: Version workflows for backward compatibility

## Conclusion

The Workflow system in PepperPy provides a flexible and extensible framework for building complex workflows. Following these guidelines ensures consistent implementation and integration with the broader framework. 