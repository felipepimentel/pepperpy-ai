---
description: ALWAYS use when implementing or modifying RAG (Retrieval Augmented Generation) components to ensure consistent implementation patterns and integration. This rule defines standards for retrieval, content processing, and prompt augmentation.
globs: ["pepperpy/rag/**/*.py", "pepperpy/**/retrieval.py", "pepperpy/**/augmentation.py"]
version: 1.0
priority: high
tags: ["rag", "retrieval", "augmentation", "llm", "embedding", "vectorstores"]
---

<?xml version="1.0" encoding="UTF-8"?>
<rule>
  <metadata>
    <n>rag_system_standards</n>
    <description>ALWAYS use when implementing or modifying RAG (Retrieval Augmented Generation) components to ensure consistent implementation patterns and integration. This rule defines standards for retrieval, content processing, and prompt augmentation.</description>
    <priority>high</priority>
    <version>1.0</version>
    <tags>
      <tag>rag</tag>
      <tag>retrieval</tag>
      <tag>augmentation</tag>
      <tag>llm</tag>
      <tag>embedding</tag>
      <tag>vectorstores</tag>
    </tags>
  </metadata>

  <filters>
    <filter>
      <type>file_extension</type>
      <pattern>\.py$</pattern>
      <description>Match Python files</description>
    </filter>
    <filter>
      <type>directory</type>
      <pattern>pepperpy/rag/</pattern>
      <description>Match files in the RAG module</description>
    </filter>
  </filters>

  <actions>
    <action>
      <type>validate</type>
      <conditions>
        <condition>
          <pattern>(?s)class\s+\w+(?:RetrieverInterface|Retriever|QueryEngine|Augmenter|Chunker|Indexer|Embedder|VectorStore)</pattern>
          <message>Use consistent naming for RAG-related components</message>
        </condition>
        <condition>
          <pattern>(?s)from typing import .*?Optional.*?from</pattern>
          <message>All retrieval methods must handle Optional parameters</message>
        </condition>
        <condition>
          <pattern>(?s)async def\s+retrieve|async def\s+query|async def\s+search|async def\s+get_relevant</pattern>
          <message>Retrieval operations should be implemented as async methods</message>
        </condition>
        <condition>
          <pattern>(?s)def\s+preprocess_text|def\s+chunk_text|def\s+clean_text</pattern>
          <message>Text preprocessing methods should follow standard naming</message>
        </condition>
        <condition>
          <pattern>(?s)def\s+score_results|def\s+rank_results|def\s+filter_results</pattern>
          <message>Result processing methods should follow standard naming</message>
        </condition>
        <condition>
          <pattern>(?s)class\s+\w+Config\(BaseModel\)</pattern>
          <message>Use Pydantic models for RAG component configuration</message>
        </condition>
      </conditions>
    </action>
    <action>
      <type>suggest</type>
      <guidelines>
        <architecture>
          <component_layers>
            <layer>
              <name>Document Processing</name>
              <components>
                <component>DocumentLoader</component>
                <component>TextChunker</component>
                <component>TextPreprocessor</component>
              </components>
              <description>Handles loading, chunking, and preprocessing of documents</description>
            </layer>
            <layer>
              <name>Indexing</name>
              <components>
                <component>Embedder</component>
                <component>VectorStore</component>
                <component>Indexer</component>
              </components>
              <description>Manages embedding and indexing of documents</description>
            </layer>
            <layer>
              <name>Retrieval</name>
              <components>
                <component>Retriever</component>
                <component>QueryEngine</component>
                <component>RelevanceScorer</component>
              </components>
              <description>Handles query processing and document retrieval</description>
            </layer>
            <layer>
              <name>Augmentation</name>
              <components>
                <component>PromptAugmenter</component>
                <component>ContextFormatter</component>
                <component>LLMIntegration</component>
              </components>
              <description>Integrates retrieved context with LLM prompts</description>
            </layer>
          </component_layers>
        </architecture>

        <standards>
          <chunking>
            <rule>Implement parameterized chunking strategies (fixed size, semantic, etc.)</rule>
            <rule>Include overlap parameter for continuous context</rule>
            <rule>Preserve metadata during chunking</rule>
            <example>
              <![CDATA[
class TextChunker:
    def __init__(
        self, 
        strategy: ChunkingStrategy = ChunkingStrategy.FIXED_SIZE,
        chunk_size: int = 1000,
        chunk_overlap: int = 200,
        preserve_metadata: bool = True
    ):
        self.strategy = strategy
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.preserve_metadata = preserve_metadata
        
    async def chunk_text(
        self, 
        text: str, 
        metadata: Optional[Dict[str, Any]] = None
    ) -> List[TextChunk]:
        """Chunk text according to the selected strategy.
        
        Args:
            text: The text to chunk
            metadata: Optional metadata to preserve
            
        Returns:
            List of TextChunk objects
        """
        # Implementation based on selected strategy
              ]]>
            </example>
          </chunking>

          <retrieval>
            <rule>Support multiple retrieval strategies (similarity, hybrid, etc.)</rule>
            <rule>Include relevance scoring and filtering</rule>
            <rule>Implement pagination for large result sets</rule>
            <example>
              <![CDATA[
class QueryEngine:
    def __init__(
        self,
        retriever: BaseRetriever,
        scorer: Optional[RelevanceScorer] = None,
        top_k: int = 5
    ):
        self.retriever = retriever
        self.scorer = scorer or DefaultRelevanceScorer()
        self.top_k = top_k
        
    async def query(
        self,
        query: str,
        filters: Optional[Dict[str, Any]] = None,
        top_k: Optional[int] = None
    ) -> List[RetrievalResult]:
        """Retrieve and score relevant documents.
        
        Args:
            query: The query string
            filters: Optional filters to apply
            top_k: Optional override for number of results
            
        Returns:
            List of scored retrieval results
        """
        # Retrieval implementation
              ]]>
            </example>
          </retrieval>

          <augmentation>
            <rule>Implement context length management for LLM constraints</rule>
            <rule>Support different formatting templates</rule>
            <rule>Include relevance-based context ordering</rule>
            <example>
              <![CDATA[
class PromptAugmenter:
    def __init__(
        self,
        template: str = "{query}\n\nContext information:\n{context}",
        max_context_length: int = 3000,
        order_by_relevance: bool = True
    ):
        self.template = template
        self.max_context_length = max_context_length
        self.order_by_relevance = order_by_relevance
        
    def augment_prompt(
        self,
        query: str,
        retrieved_context: List[RetrievalResult]
    ) -> str:
        """Augment prompt with retrieved context.
        
        Args:
            query: The original query
            retrieved_context: List of retrieval results
            
        Returns:
            Augmented prompt
        """
        # Implementation of prompt augmentation
              ]]>
            </example>
          </augmentation>
        </standards>
      </guidelines>
    </action>
  </actions>

  <examples>
    <example>
      <correct>
        <description>Complete implementation of a RAG retriever</description>
        <content>
          <![CDATA[
from typing import Dict, List, Optional, Any

from pepperpy.rag.base import BaseRetriever, RetrievalResult
from pepperpy.embedding.providers import OpenAIEmbedding
from pepperpy.storage.providers import VectorStoreProvider

class HybridRetriever(BaseRetriever):
    """Hybrid retriever combining semantic and keyword search.
    
    This retriever implements a hybrid approach to document retrieval,
    combining both vector similarity search and keyword-based search
    for improved accuracy.
    """
    
    def __init__(
        self,
        vector_store: VectorStoreProvider,
        embedding_provider: OpenAIEmbedding,
        keyword_weight: float = 0.3,
        semantic_weight: float = 0.7,
        top_k: int = 5
    ):
        """Initialize hybrid retriever.
        
        Args:
            vector_store: Vector store provider for embeddings
            embedding_provider: Provider to generate embeddings
            keyword_weight: Weight for keyword search results
            semantic_weight: Weight for semantic search results
            top_k: Number of results to return
        """
        self.vector_store = vector_store
        self.embedding_provider = embedding_provider
        self.keyword_weight = keyword_weight
        self.semantic_weight = semantic_weight
        self.top_k = top_k
        
    async def retrieve(
        self,
        query: str,
        filters: Optional[Dict[str, Any]] = None,
        top_k: Optional[int] = None
    ) -> List[RetrievalResult]:
        """Retrieve documents using hybrid search.
        
        Args:
            query: The query string
            filters: Optional metadata filters
            top_k: Optional override for number of results
            
        Returns:
            List of retrieval results
        """
        k = top_k or self.top_k
        
        # Generate query embedding
        query_embedding = await self.embedding_provider.embed_query(query)
        
        # Perform semantic search
        semantic_results = await self.vector_store.similarity_search(
            query_embedding,
            filters=filters,
            k=k * 2  # Get more results for reranking
        )
        
        # Perform keyword search 
        keyword_results = await self.keyword_search(query, filters, k * 2)
        
        # Combine and rerank results
        combined_results = self._merge_and_rerank(
            semantic_results, 
            keyword_results,
            query
        )
        
        # Return top k results
        return combined_results[:k]
          ]]>
        </content>
      </correct>
      <incorrect>
        <description>Poor implementation with inconsistent APIs and missing features</description>
        <content>
          <![CDATA[
class SimpleRetriever:
    def __init__(self, vector_db):
        self.vector_db = vector_db
    
    def get_results(self, q, n=5):
        # No support for async operations
        # Missing type hints
        # Inconsistent parameter naming
        # No error handling
        emb = self.get_embedding(q)
        return self.vector_db.search(emb, n)
        
    def get_embedding(self, text):
        # Direct dependency on implementation details
        # No abstraction for embedding provider
        import openai
        return openai.Embedding.create(text)
          ]]>
        </content>
      </incorrect>
    </example>
  </examples>
</rule> 