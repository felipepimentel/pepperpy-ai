---
title: Testing Rules
description: Guidelines for unit, integration, and lifecycle tests, including usage of mocks and type checks.
globs: tests/**/*.py
---

# Testing Guidelines

## Test Categories

### 1. Unit Tests
- Test individual components in isolation
- Use mocks for external dependencies
- Validate type annotations
- Test error handling

```python
import pytest
from unittest.mock import Mock
from pepperpy.agents import Agent
from pepperpy.types import Message

def test_agent_message_handling():
    """Test agent's message handling capabilities."""
    mock_provider = Mock()
    agent = Agent(provider=mock_provider)
    
    message = Message(
        sender="test",
        content={"query": "test"}
    )
    
    result = agent.process_message(message)
    assert result.status == "success"
    mock_provider.process.assert_called_once_with(message)
```

### 2. Integration Tests
- Test component interactions
- Use test configurations
- Validate end-to-end workflows
- Test with real dependencies

```python
@pytest.mark.integration
async def test_agent_provider_integration():
    """Test agent interaction with actual provider."""
    config = TestConfig()
    agent = Agent(config=config)
    provider = OpenAIProvider()
    
    await agent.initialize()
    await provider.initialize()
    
    result = await agent.execute_with_provider(
        provider,
        task="test task"
    )
    
    assert result.success
    assert isinstance(result.response, str)
```

### 3. Performance Tests
- Measure response times
- Test under load
- Validate resource usage
- Check memory leaks

```python
@pytest.mark.performance
async def test_agent_performance():
    """Test agent performance under load."""
    agent = Agent()
    start_time = time.time()
    
    results = await asyncio.gather(*[
        agent.process_message(create_test_message())
        for _ in range(100)
    ])
    
    duration = time.time() - start_time
    assert duration < 5.0  # Must complete within 5 seconds
    assert all(r.success for r in results)
```

### 4. Type Tests
- Validate type hints
- Test generic implementations
- Check protocol adherence

```python
from typing import Protocol, runtime_checkable

@runtime_checkable
class MessageProcessor(Protocol):
    async def process_message(self, message: Message) -> Response: ...

def test_type_compliance():
    """Test type compliance of components."""
    agent = Agent()
    assert isinstance(agent, MessageProcessor)
```

## Test Configuration

### Environment Setup
```python
@pytest.fixture
def test_config():
    """Provide test configuration."""
    return {
        "model": "test-model",
        "max_tokens": 100,
        "temperature": 0.5
    }

@pytest.fixture
async def initialized_agent(test_config):
    """Provide initialized agent for tests."""
    agent = Agent(config=test_config)
    await agent.initialize()
    yield agent
    await agent.cleanup()
```

### Mock Setup
```python
@pytest.fixture
def mock_provider():
    """Provide mock provider for testing."""
    provider = Mock()
    provider.process.return_value = {
        "status": "success",
        "response": "test response"
    }
    return provider
```

## Coverage Requirements
- All public APIs must be tested
- All error paths must be tested
- All async code must be tested

## Performance Requirements

- Response time < 100ms for simple operations
- Memory usage < 100MB per instance
- No memory leaks after 1000 operations
- Successful handling of 100 concurrent requests

## Test Organization

```plaintext
tests/
├── unit/
│   ├── test_agents.py
│   ├── test_providers.py
│   └── test_protocol.py
├── integration/
│   ├── test_agent_provider.py
│   └── test_workflows.py
├── performance/
│   ├── test_load.py
│   └── test_memory.py
└── conftest.py
```

## Continuous Integration

- All tests must pass before merge
- Coverage report required
- Performance benchmarks must meet thresholds
- Type checking must pass