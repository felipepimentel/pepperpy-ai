---
description: ALWAYS use when implementing or modifying observability components to ensure consistent patterns and comprehensive monitoring. This rule defines standards for logging, metrics, tracing, and alerting.
globs: ["pepperpy/observability/**/*.py", "pepperpy/**/logging*.py", "pepperpy/**/metrics*.py", "pepperpy/**/tracing*.py"]
version: 1.0
priority: high
tags: ["observability", "monitoring", "logging", "metrics", "tracing", "alerting"]
---

<?xml version="1.0" encoding="UTF-8"?>
<rule>
  <metadata>
    <n>observability_standards</n>
    <description>ALWAYS use when implementing or modifying observability components to ensure consistent patterns and comprehensive monitoring. This rule defines standards for logging, metrics, tracing, and alerting.</description>
    <priority>high</priority>
    <version>1.0</version>
    <tags>
      <tag>observability</tag>
      <tag>monitoring</tag>
      <tag>logging</tag>
      <tag>metrics</tag>
      <tag>tracing</tag>
      <tag>alerting</tag>
    </tags>
  </metadata>

  <filters>
    <filter>
      <type>file_extension</type>
      <pattern>\.py$</pattern>
      <description>Match Python files</description>
    </filter>
    <filter>
      <type>directory</type>
      <pattern>observability/|monitoring/</pattern>
      <description>Match files in observability or monitoring related directories</description>
    </filter>
    <filter>
      <type>content</type>
      <pattern>(?:logging|logger|metrics|tracing|spans|monitor|telemetry)</pattern>
      <description>Match files containing observability related terms</description>
    </filter>
  </filters>

  <actions>
    <action>
      <type>validate</type>
      <conditions>
        <condition>
          <pattern>(?s)class\s+\w+(?:Logger|Monitor|Tracer|Metrics|Reporter)</pattern>
          <message>Use consistent naming for observability components</message>
        </condition>
        <condition>
          <pattern>(?s)import\s+logging</pattern>
          <message>Use the standard Python logging module</message>
        </condition>
        <condition>
          <pattern>(?s)from typing import .*?Optional.*?Dict</pattern>
          <message>Include proper type annotations for observability structures</message>
        </condition>
        <condition>
          <pattern>(?s)def\s+log_\w+|def\s+trace_\w+|def\s+record_\w+|def\s+measure_\w+</pattern>
          <message>Observation methods should follow standard naming</message>
        </condition>
        <condition>
          <pattern>(?s)def\s+start_span|def\s+end_span|def\s+with_span</pattern>
          <message>Tracing methods should follow standard naming</message>
        </condition>
        <condition>
          <pattern>(?s)class\s+\w+Config\(BaseModel\)</pattern>
          <message>Use Pydantic models for observability configuration</message>
        </condition>
        <condition>
          <pattern>(?s)async def\s+\w+</pattern>
          <message>Observability methods should be async-compatible</message>
        </condition>
      </conditions>
    </action>
    <action>
      <type>suggest</type>
      <guidelines>
        <observability_architecture>
          <layer>
            <n>Core Components</n>
            <components>
              <component>LoggerFactory</component>
              <component>MetricsRegistry</component>
              <component>TracerProvider</component>
              <component>HealthService</component>
            </components>
            <description>Central observability components that provide core functionality</description>
          </layer>
          <layer>
            <n>Instrumentation</n>
            <components>
              <component>Middleware</component>
              <component>Decorators</component>
              <component>ContextManagers</component>
              <component>AspectWrappers</component>
            </components>
            <description>Components that intercept and monitor code execution</description>
          </layer>
          <layer>
            <n>Exporters</n>
            <components>
              <component>PrometheusExporter</component>
              <component>JaegerExporter</component>
              <component>LogExporter</component>
              <component>MetricsExporter</component>
            </components>
            <description>Components that export observability data to external systems</description>
          </layer>
          <layer>
            <n>Aggregation</n>
            <components>
              <component>MetricsAggregator</component>
              <component>LogAggregator</component>
              <component>AlertAggregator</component>
            </components>
            <description>Components that aggregate and process observability data</description>
          </layer>
        </observability_architecture>

        <logging_standards>
          <core_principles>
            <rule>Use structured logging with context</rule>
            <rule>Include trace IDs in all log messages</rule>
            <rule>Use appropriate log levels consistently</rule>
            <rule>Include relevant metadata and avoid sensitive information</rule>
            <example>
              <![CDATA[
from typing import Dict, Any, Optional
import logging
import json
from contextvars import ContextVar
from pydantic import BaseModel
from pepperpy.core.context import get_trace_id, get_context

# Context tracking
request_context: ContextVar[Dict[str, Any]] = ContextVar("request_context", default={})

class LogEntry(BaseModel):
    """Structured log entry model."""
    
    message: str
    level: str
    timestamp: str
    trace_id: Optional[str] = None
    span_id: Optional[str] = None
    service: Optional[str] = None
    component: Optional[str] = None
    context: Dict[str, Any] = {}
    
class StructuredLogger:
    """Logger that produces structured log entries."""
    
    def __init__(self, name: str):
        """Initialize structured logger.
        
        Args:
            name: Logger name, typically module name
        """
        self.logger = logging.getLogger(name)
        self.name = name
        
    def _log(
        self,
        level: int,
        message: str,
        extra: Optional[Dict[str, Any]] = None
    ) -> None:
        """Internal logging method.
        
        Args:
            level: Log level constant
            message: Log message
            extra: Additional context data
        """
        # Get current trace context
        context = get_context()
        current_context = {
            "trace_id": get_trace_id(),
            "service": context.get("service_name", "unknown"),
            "component": context.get("component_name", self.name)
        }
        
        # Add request context
        try:
            current_context.update(request_context.get())
        except LookupError:
            pass
            
        # Add extra context if provided
        if extra:
            current_context.update(extra)
            
        # Log with full context
        self.logger.log(level, message, extra=current_context)
        
    def debug(self, message: str, **kwargs) -> None:
        """Log a debug message.
        
        Args:
            message: Log message
            **kwargs: Additional context key-value pairs
        """
        self._log(logging.DEBUG, message, kwargs)
        
    def info(self, message: str, **kwargs) -> None:
        """Log an info message.
        
        Args:
            message: Log message
            **kwargs: Additional context key-value pairs
        """
        self._log(logging.INFO, message, kwargs)
        
    def warning(self, message: str, **kwargs) -> None:
        """Log a warning message.
        
        Args:
            message: Log message
            **kwargs: Additional context key-value pairs
        """
        self._log(logging.WARNING, message, kwargs)
        
    def error(self, message: str, exc_info=False, **kwargs) -> None:
        """Log an error message.
        
        Args:
            message: Log message
            exc_info: Whether to include exception info
            **kwargs: Additional context key-value pairs
        """
        extra = kwargs.copy()
        if exc_info:
            extra["exc_info"] = True
        self._log(logging.ERROR, message, extra)
        
    def critical(self, message: str, exc_info=True, **kwargs) -> None:
        """Log a critical message.
        
        Args:
            message: Log message
            exc_info: Whether to include exception info
            **kwargs: Additional context key-value pairs
        """
        extra = kwargs.copy()
        if exc_info:
            extra["exc_info"] = True
        self._log(logging.CRITICAL, message, extra)
        
    def set_context(self, **kwargs) -> None:
        """Set context values for all subsequent logs.
        
        Args:
            **kwargs: Context key-value pairs to set
        """
        current = {}
        try:
            current = request_context.get()
        except LookupError:
            pass
            
        updated = {**current, **kwargs}
        request_context.set(updated)
              ]]>
            </example>
          </core_principles>

          <log_levels>
            <level>
              <n>DEBUG</n>
              <description>Detailed information, typically for diagnosis</description>
              <examples>
                <example>Function parameter values</example>
                <example>Intermediate calculation results</example>
                <example>Cache hit/miss details</example>
              </examples>
            </level>
            <level>
              <n>INFO</n>
              <description>Confirmation that things are working as expected</description>
              <examples>
                <example>Request received</example>
                <example>Task completed successfully</example>
                <example>Service initialized</example>
              </examples>
            </level>
            <level>
              <n>WARNING</n>
              <description>Indication that something unexpected happened</description>
              <examples>
                <example>Deprecated feature used</example>
                <example>Resource usage approaching limits</example>
                <example>Fallback mechanism activated</example>
              </examples>
            </level>
            <level>
              <n>ERROR</n>
              <description>Due to a problem, some function couldn't perform its operation</description>
              <examples>
                <example>External API unreachable</example>
                <example>Operation failed but recoverable</example>
                <example>Invalid user input rejected</example>
              </examples>
            </level>
            <level>
              <n>CRITICAL</n>
              <description>Serious error indicating system is unusable</description>
              <examples>
                <example>Database connection lost</example>
                <example>Out of memory condition</example>
                <example>Unrecoverable system error</example>
              </examples>
            </level>
          </log_levels>
        </logging_standards>

        <metrics_standards>
          <metric_types>
            <type>
              <n>Counter</n>
              <description>Cumulative metric for values that only increase</description>
              <examples>
                <example>request_count</example>
                <example>errors_total</example>
                <example>tokens_processed</example>
              </examples>
              <naming>Use _total suffix for counters</naming>
            </type>
            <type>
              <n>Gauge</n>
              <description>Metric that can increase and decrease</description>
              <examples>
                <example>active_connections</example>
                <example>memory_usage_bytes</example>
                <example>queue_size</example>
              </examples>
              <naming>Include unit in metric name</naming>
            </type>
            <type>
              <n>Histogram</n>
              <description>Samples observations and counts them in buckets</description>
              <examples>
                <example>request_duration_seconds</example>
                <example>response_size_bytes</example>
                <example>token_count</example>
              </examples>
              <naming>Include unit and measurement type</naming>
            </type>
            <type>
              <n>Summary</n>
              <description>Similar to histogram, calculates quantiles over time</description>
              <examples>
                <example>request_duration_quantiles</example>
                <example>response_time_summary</example>
              </examples>
              <naming>Use _summary or _quantiles suffix</naming>
            </type>
          </metric_types>

          <implementation>
            <example>
              <![CDATA[
from typing import Dict, Any, List, Optional, Union, ClassVar
import time
from enum import Enum
from contextlib import contextmanager
from pydantic import BaseModel

class MetricType(str, Enum):
    """Types of metrics supported."""
    
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    SUMMARY = "summary"
    
class MetricDefinition(BaseModel):
    """Definition of a metric."""
    
    name: str
    description: str
    type: MetricType
    labels: List[str] = []
    unit: Optional[str] = None
    
    class Config:
        """Pydantic configuration."""
        
        extra = "forbid"
        
class MetricsService:
    """Service for collecting and exporting metrics."""
    
    _instance: ClassVar[Optional["MetricsService"]] = None
    
    def __init__(self, namespace: str = "pepperpy"):
        """Initialize metrics service.
        
        Args:
            namespace: Metrics namespace prefix
        """
        self.namespace = namespace
        self.metrics = {}
        
    @classmethod
    def get_instance(cls, namespace: str = "pepperpy") -> "MetricsService":
        """Get singleton instance.
        
        Args:
            namespace: Metrics namespace prefix
            
        Returns:
            Metrics service instance
        """
        if cls._instance is None:
            cls._instance = cls(namespace=namespace)
        return cls._instance
        
    def create_counter(
        self,
        name: str,
        description: str,
        labels: List[str] = []
    ) -> "Counter":
        """Create a counter metric.
        
        Args:
            name: Metric name
            description: Metric description
            labels: Label names
            
        Returns:
            Counter metric
        """
        full_name = f"{self.namespace}_{name}"
        metric = Counter(full_name, description, labels)
        self.metrics[full_name] = metric
        return metric
        
    def create_gauge(
        self,
        name: str,
        description: str,
        labels: List[str] = []
    ) -> "Gauge":
        """Create a gauge metric.
        
        Args:
            name: Metric name
            description: Metric description
            labels: Label names
            
        Returns:
            Gauge metric
        """
        full_name = f"{self.namespace}_{name}"
        metric = Gauge(full_name, description, labels)
        self.metrics[full_name] = metric
        return metric
        
    def create_histogram(
        self,
        name: str,
        description: str,
        labels: List[str] = [],
        buckets: Optional[List[float]] = None
    ) -> "Histogram":
        """Create a histogram metric.
        
        Args:
            name: Metric name
            description: Metric description
            labels: Label names
            buckets: Histogram buckets
            
        Returns:
            Histogram metric
        """
        full_name = f"{self.namespace}_{name}"
        metric = Histogram(full_name, description, labels, buckets)
        self.metrics[full_name] = metric
        return metric
        
class Counter:
    """Counter metric type."""
    
    def __init__(self, name: str, description: str, labels: List[str] = []):
        """Initialize counter.
        
        Args:
            name: Metric name
            description: Metric description
            labels: Label names
        """
        self.name = name
        self.description = description
        self.label_names = labels
        self.values = {}
        
    def increment(
        self,
        value: float = 1.0,
        labels: Optional[Dict[str, str]] = None
    ) -> None:
        """Increment counter value.
        
        Args:
            value: Amount to increment by
            labels: Label values
        """
        label_key = self._get_label_key(labels)
        current = self.values.get(label_key, 0.0)
        self.values[label_key] = current + value
        
    def _get_label_key(self, labels: Optional[Dict[str, str]]) -> str:
        """Get key for labels.
        
        Args:
            labels: Label values
            
        Returns:
            String key for label set
        """
        if not labels:
            return ""
            
        parts = []
        for name in self.label_names:
            value = labels.get(name, "")
            parts.append(f"{name}:{value}")
            
        return ",".join(parts)
    
class Gauge:
    """Gauge metric type."""
    
    def __init__(self, name: str, description: str, labels: List[str] = []):
        """Initialize gauge.
        
        Args:
            name: Metric name
            description: Metric description
            labels: Label names
        """
        self.name = name
        self.description = description
        self.label_names = labels
        self.values = {}
        
    def set(
        self,
        value: float,
        labels: Optional[Dict[str, str]] = None
    ) -> None:
        """Set gauge value.
        
        Args:
            value: Gauge value
            labels: Label values
        """
        label_key = self._get_label_key(labels)
        self.values[label_key] = value
        
    def _get_label_key(self, labels: Optional[Dict[str, str]]) -> str:
        """Get key for labels.
        
        Args:
            labels: Label values
            
        Returns:
            String key for label set
        """
        if not labels:
            return ""
            
        parts = []
        for name in self.label_names:
            value = labels.get(name, "")
            parts.append(f"{name}:{value}")
            
        return ",".join(parts)
        
class Histogram:
    """Histogram metric type."""
    
    def __init__(
        self,
        name: str,
        description: str,
        labels: List[str] = [],
        buckets: Optional[List[float]] = None
    ):
        """Initialize histogram.
        
        Args:
            name: Metric name
            description: Metric description
            labels: Label names
            buckets: Histogram buckets
        """
        self.name = name
        self.description = description
        self.label_names = labels
        self.buckets = buckets or [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10]
        self.values = {}
        
    def observe(
        self,
        value: float,
        labels: Optional[Dict[str, str]] = None
    ) -> None:
        """Record an observation.
        
        Args:
            value: Observed value
            labels: Label values
        """
        label_key = self._get_label_key(labels)
        if label_key not in self.values:
            self.values[label_key] = []
        self.values[label_key].append(value)
        
    @contextmanager
    def time(self, labels: Optional[Dict[str, str]] = None):
        """Time a block of code.
        
        Args:
            labels: Label values
            
        Yields:
            Timer context manager
        """
        start_time = time.time()
        yield
        duration = time.time() - start_time
        self.observe(duration, labels)
        
    def _get_label_key(self, labels: Optional[Dict[str, str]]) -> str:
        """Get key for labels.
        
        Args:
            labels: Label values
            
        Returns:
            String key for label set
        """
        if not labels:
            return ""
            
        parts = []
        for name in self.label_names:
            value = labels.get(name, "")
            parts.append(f"{name}:{value}")
            
        return ",".join(parts)
              ]]>
            </example>
          </implementation>
        </metrics_standards>

        <tracing_standards>
          <core_principles>
            <rule>Use distributed tracing for end-to-end visibility</rule>
            <rule>Propagate context across system boundaries</rule>
            <rule>Add relevant attributes to spans</rule>
            <rule>Create spans for all significant operations</rule>
            <example>
              <![CDATA[
from typing import Dict, Any, Optional, AsyncContextManager
import asyncio
import contextvars
from contextlib import asynccontextmanager, contextmanager
from pydantic import BaseModel
import inspect
import functools

# Context variable for current span
current_span: contextvars.ContextVar[Optional[Dict[str, Any]]] = contextvars.ContextVar(
    "current_span", default=None
)

# Context variable for trace ID
trace_id: contextvars.ContextVar[Optional[str]] = contextvars.ContextVar(
    "trace_id", default=None
)

class Span(BaseModel):
    """Tracing span model."""
    
    name: str
    trace_id: str
    span_id: str
    parent_span_id: Optional[str] = None
    start_time: float
    end_time: Optional[float] = None
    attributes: Dict[str, Any] = {}
    events: List[Dict[str, Any]] = []
    
class TracingService:
    """Service for distributed tracing."""
    
    def __init__(self, service_name: str):
        """Initialize tracing service.
        
        Args:
            service_name: Name of the service
        """
        self.service_name = service_name
        
    @contextmanager
    def span(
        self,
        name: str,
        attributes: Optional[Dict[str, Any]] = None
    ):
        """Create a tracing span.
        
        Args:
            name: Span name
            attributes: Span attributes
            
        Yields:
            Active span object
        """
        span = self.start_span(name, attributes)
        try:
            yield span
        finally:
            self.end_span(span)
            
    @asynccontextmanager
    async def async_span(
        self,
        name: str,
        attributes: Optional[Dict[str, Any]] = None
    ) -> AsyncContextManager:
        """Create an async tracing span.
        
        Args:
            name: Span name
            attributes: Span attributes
            
        Yields:
            Active span object
        """
        span = self.start_span(name, attributes)
        try:
            yield span
        finally:
            self.end_span(span)
            
    def start_span(
        self,
        name: str,
        attributes: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Start a new span.
        
        Args:
            name: Span name
            attributes: Span attributes
            
        Returns:
            Span object
        """
        # Implementation of span creation
        return {}
        
    def end_span(self, span: Dict[str, Any]) -> None:
        """End a span.
        
        Args:
            span: Span to end
        """
        # Implementation of span completion
        pass
        
    def trace(self, name: Optional[str] = None, attributes: Optional[Dict[str, Any]] = None):
        """Decorator for tracing functions.
        
        Args:
            name: Optional span name (defaults to function name)
            attributes: Optional span attributes
            
        Returns:
            Decorator function
        """
        def decorator(func):
            @functools.wraps(func)
            def sync_wrapper(*args, **kwargs):
                span_name = name or f"{func.__module__}.{func.__qualname__}"
                with self.span(span_name, attributes) as span:
                    return func(*args, **kwargs)
                    
            @functools.wraps(func)
            async def async_wrapper(*args, **kwargs):
                span_name = name or f"{func.__module__}.{func.__qualname__}"
                async with self.async_span(span_name, attributes) as span:
                    return await func(*args, **kwargs)
                    
            if asyncio.iscoroutinefunction(func):
                return async_wrapper
            else:
                return sync_wrapper
                
        return decorator
              ]]>
            </example>
          </core_principles>

          <span_naming>
            <rule>Use concise but descriptive span names</rule>
            <rule>Include operation and target in the name</rule>
            <rule>Follow [operation].[target] format where applicable</rule>
            <examples>
              <span>
                <name>http.request</name>
                <usage>HTTP request processing</usage>
                <attributes>http.method, http.url, http.status_code</attributes>
              </span>
              <span>
                <name>db.query</name>
                <usage>Database query execution</usage>
                <attributes>db.system, db.name, db.statement</attributes>
              </span>
              <span>
                <name>llm.generate</name>
                <usage>LLM text generation</usage>
                <attributes>llm.model, llm.tokens, llm.provider</attributes>
              </span>
            </examples>
          </span_naming>
        </tracing_standards>

        <health_monitoring>
          <health_check>
            <rule>Implement liveness checks for service health</rule>
            <rule>Implement readiness checks for service availability</rule>
            <rule>Include dependency health in checks</rule>
            <example>
              <![CDATA[
from typing import Dict, Any, List, Optional, Callable, Awaitable
import asyncio
from enum import Enum
from pydantic import BaseModel

class HealthStatus(str, Enum):
    """Health status values."""
    
    UP = "UP"
    DOWN = "DOWN"
    DEGRADED = "DEGRADED"
    
class DependencyHealth(BaseModel):
    """Health status for a dependency."""
    
    name: str
    status: HealthStatus
    details: Dict[str, Any] = {}
    
class HealthCheck(BaseModel):
    """Health check result."""
    
    status: HealthStatus
    version: str
    dependencies: List[DependencyHealth] = []
    details: Dict[str, Any] = {}
    
class HealthService:
    """Service for health monitoring."""
    
    def __init__(self, version: str):
        """Initialize health service.
        
        Args:
            version: Application version
        """
        self.version = version
        self.dependency_checks = {}
        
    def register_dependency(
        self,
        name: str,
        check_func: Callable[[], Awaitable[DependencyHealth]]
    ) -> None:
        """Register a dependency health check.
        
        Args:
            name: Dependency name
            check_func: Async function that returns dependency health
        """
        self.dependency_checks[name] = check_func
        
    async def check_health(self) -> HealthCheck:
        """Check overall system health.
        
        Returns:
            Health check result
        """
        # Check all dependencies
        dependency_results = []
        overall_status = HealthStatus.UP
        
        # Run all checks in parallel
        if self.dependency_checks:
            tasks = [
                self._check_dependency(name, check_func)
                for name, check_func in self.dependency_checks.items()
            ]
            dependency_results = await asyncio.gather(*tasks)
            
            # Determine overall status
            for dep in dependency_results:
                if dep.status == HealthStatus.DOWN:
                    overall_status = HealthStatus.DOWN
                    break
                elif dep.status == HealthStatus.DEGRADED and overall_status != HealthStatus.DOWN:
                    overall_status = HealthStatus.DEGRADED
                    
        # Create health check result
        return HealthCheck(
            status=overall_status,
            version=self.version,
            dependencies=dependency_results
        )
        
    async def _check_dependency(
        self,
        name: str,
        check_func: Callable[[], Awaitable[DependencyHealth]]
    ) -> DependencyHealth:
        """Check a dependency's health.
        
        Args:
            name: Dependency name
            check_func: Health check function
            
        Returns:
            Dependency health status
        """
        try:
            # Call the check function
            return await check_func()
        except Exception as e:
            # If check fails, dependency is down
            return DependencyHealth(
                name=name,
                status=HealthStatus.DOWN,
                details={"error": str(e), "error_type": type(e).__name__}
            )
              ]]>
            </example>
          </health_check>
        </health_monitoring>
      </guidelines>
    </action>
  </actions>

  <examples>
    <example>
      <correct>
        <description>Well-implemented observability integration</description>
        <content>
          <![CDATA[
from typing import Dict, Any, Optional
import logging
import time
from contextlib import asynccontextmanager
from uuid import uuid4

from pepperpy.observability.logging import StructuredLogger
from pepperpy.observability.metrics import MetricsService
from pepperpy.observability.tracing import TracingService
from pepperpy.core.context import get_context

# Create observability components
logger = StructuredLogger(__name__)
metrics = MetricsService.get_instance(namespace="agent_service")
tracer = TracingService(service_name="agent_service")

# Define metrics
request_counter = metrics.create_counter(
    "requests_total",
    "Total number of requests processed",
    ["agent_type", "operation", "status"]
)

processing_time = metrics.create_histogram(
    "processing_time_seconds",
    "Time taken to process requests",
    ["agent_type", "operation"]
)

class ObservableComponent:
    """Component with integrated observability.
    
    This example demonstrates proper integration of logging,
    metrics, and tracing in a reusable component.
    """
    
    def __init__(self, name: str, component_type: str):
        """Initialize component with observability.
        
        Args:
            name: Component name
            component_type: Component type
        """
        self.name = name
        self.component_type = component_type
        
    async def process_request(
        self,
        request_id: str,
        operation: str,
        data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Process a request with full observability.
        
        Args:
            request_id: Request identifier
            operation: Operation to perform
            data: Request data
            
        Returns:
            Operation result
        """
        # Set up context for logging
        logger.set_context(
            request_id=request_id,
            component_name=self.name,
            component_type=self.component_type
        )
        
        # Log request received
        logger.info(
            f"Request received: {operation}",
            operation=operation,
            data_size=len(str(data))
        )
        
        # Create span for the operation
        async with tracer.async_span(
            name=f"{self.component_type}.{operation}",
            attributes={
                "component.name": self.name,
                "component.type": self.component_type,
                "request.id": request_id,
                "operation": operation
            }
        ) as span:
            # Use histogram to measure processing time
            with processing_time.time(
                labels={"agent_type": self.component_type, "operation": operation}
            ):
                try:
                    # Record event at processing start
                    span.add_event("processing_started", {
                        "timestamp": time.time(),
                        "data_size": len(str(data))
                    })
                    
                    # Actual processing logic
                    result = await self._execute_operation(operation, data, span)
                    
                    # Record successful completion
                    logger.info(
                        f"Request processed successfully: {operation}",
                        operation=operation,
                        result_size=len(str(result))
                    )
                    
                    # Update success metrics
                    request_counter.increment(
                        labels={
                            "agent_type": self.component_type,
                            "operation": operation,
                            "status": "success"
                        }
                    )
                    
                    return result
                    
                except Exception as e:
                    # Log error with context
                    logger.error(
                        f"Error processing request: {str(e)}",
                        operation=operation,
                        error_type=type(e).__name__,
                        exc_info=True
                    )
                    
                    # Record error in span
                    span.add_event("error", {
                        "error_type": type(e).__name__,
                        "error_message": str(e)
                    })
                    
                    # Update error metrics
                    request_counter.increment(
                        labels={
                            "agent_type": self.component_type,
                            "operation": operation,
                            "status": "error"
                        }
                    )
                    
                    # Re-raise for caller
                    raise
    
    async def _execute_operation(
        self,
        operation: str,
        data: Dict[str, Any],
        parent_span: Any
    ) -> Dict[str, Any]:
        """Execute the specified operation.
        
        Args:
            operation: Operation to execute
            data: Operation data
            parent_span: Parent tracing span
            
        Returns:
            Operation result
        """
        # Create child span for specific operation
        async with tracer.async_span(
            name=f"execute.{operation}",
            attributes={"data_size": len(str(data))}
        ) as span:
            # Log execution details
            logger.debug(
                f"Executing operation: {operation}",
                operation_data=data
            )
            
            # Simulated operation result
            await asyncio.sleep(0.1)  # Simulate processing
            
            return {
                "result": f"Processed {operation}",
                "timestamp": time.time(),
                "id": str(uuid4())
            }
          ]]>
        </content>
      </correct>
      <incorrect>
        <description>Poorly implemented observability with anti-patterns</description>
        <content>
          <![CDATA[
import time
import logging

# Anti-pattern: Global logger without structure
logger = logging.getLogger()

class SimpleProcessor:
    def __init__(self, name):
        self.name = name
        
    # Anti-pattern: Missing async, improper error handling
    def process(self, data):
        # Anti-pattern: Print statement instead of logging
        print(f"Processing data: {data}")
        
        # Anti-pattern: Manual timing without proper metrics
        start_time = time.time()
        
        try:
            # Actual processing
            result = self._process_internal(data)
            
            # Anti-pattern: String interpolation in log
            logger.info("Process completed in " + str(time.time() - start_time) + " seconds")
            
            # Anti-pattern: No structured result
            return result
        except Exception as e:
            # Anti-pattern: Generic error handling
            logger.error(f"Error: {e}")
            return None
            
    def _process_internal(self, data):
        # Anti-pattern: No tracing or metrics
        # Anti-pattern: No context propagation
        
        # Some processing logic
        if data.get("id") is None:
            # Anti-pattern: No error details
            raise Exception("Invalid data")
            
        # Anti-pattern: No detailed logs for debugging
        return {"status": "done"}
        
# Anti-pattern: Manual request counting
request_count = 0

def handle_request(data):
    # Anti-pattern: Global state modification
    global request_count
    request_count += 1
    
    # Anti-pattern: No context management
    # Anti-pattern: No request ID tracking
    processor = SimpleProcessor("default")
    return processor.process(data)
          ]]>
        </content>
      </incorrect>
    </example>
  </examples>
</rule> 