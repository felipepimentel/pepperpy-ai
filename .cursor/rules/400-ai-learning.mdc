---
description: ALWAYS use when reading or writing AI knowledge data to ensure consistent knowledge management. This rule provides complete and unambiguous definitions for AI's incremental learning system.
globs: ["pepperpy/capabilities/**/*.py", "pepperpy/agents/**/*.py", "pepperpy/llm/**/*.py"]
version: 1.1
priority: high
tags: ["ai", "learning", "knowledge", "capabilities"]
---

<?xml version="1.0" encoding="UTF-8"?>
<rule>
  <metadata>
    <n>ai_learning_standards</n>
    <description>ALWAYS use when reading or writing AI knowledge data to ensure consistent knowledge management. This rule provides complete and unambiguous definitions for AI's incremental learning system.</description>
    <priority>high</priority>
    <version>1.1</version>
    <tags>
      <tag>ai</tag>
      <tag>learning</tag>
      <tag>knowledge</tag>
      <tag>capabilities</tag>
    </tags>
  </metadata>

  <filters>
    <filter>
      <type>file_extension</type>
      <pattern>\.py$</pattern>
      <description>Match Python files</description>
    </filter>
    <filter>
      <type>content</type>
      <pattern>(?:Knowledge|Learning|Capability|Reasoning|Planning|Intelligence)</pattern>
      <description>Match files containing AI learning related terms</description>
    </filter>
  </filters>

  <actions>
    <action>
      <type>validate</type>
      <conditions>
        <condition>
          <pattern>(?s)class\s+\w+(?:Capability|Knowledge|Learning|Memory)</pattern>
          <message>Use consistent naming for AI learning components</message>
        </condition>
        <condition>
          <pattern>(?s)from typing import .*?Optional.*?Dict</pattern>
          <message>Include proper type annotations for knowledge structures</message>
        </condition>
        <condition>
          <pattern>(?s)def\s+store_knowledge|def\s+retrieve_knowledge|def\s+update_knowledge</pattern>
          <message>Knowledge management methods should follow standard naming</message>
        </condition>
        <condition>
          <pattern>(?s)def\s+learn_from|def\s+adapt_to|def\s+improve_with</pattern>
          <message>Learning methods should follow standard naming</message>
        </condition>
        <condition>
          <pattern>(?s)class\s+\w+Schema\(BaseModel\)</pattern>
          <message>Use Pydantic models for knowledge schemas</message>
        </condition>
      </conditions>
    </action>
    <action>
      <type>suggest</type>
      <guidelines>
        <knowledge_representation>
          <data_structure>
            <rule>Use structured knowledge representation</rule>
            <rule>Include metadata with all knowledge entries</rule>
            <rule>Maintain provenance information</rule>
            <example>
              <![CDATA[
from pydantic import BaseModel, Field
from typing import Dict, List, Optional, Any
from datetime import datetime
from uuid import UUID, uuid4

class KnowledgeEntry(BaseModel):
    """Represents a unit of knowledge in the system."""
    
    id: UUID = Field(default_factory=uuid4)
    content: Dict[str, Any]
    source: str
    confidence: float = Field(ge=0.0, le=1.0)
    created_at: datetime = Field(default_factory=datetime.now)
    last_accessed: Optional[datetime] = None
    access_count: int = 0
    tags: List[str] = Field(default_factory=list)
    
    def update_access_stats(self) -> None:
        """Update access statistics when this knowledge is retrieved."""
        self.last_accessed = datetime.now()
        self.access_count += 1
              ]]>
            </example>
          </data_structure>

          <knowledge_types>
            <rule>Distinguish between different knowledge types</rule>
            <rule>Implement specialized handling for each type</rule>
            <example>
              <![CDATA[
from enum import Enum, auto

class KnowledgeType(Enum):
    """Types of knowledge in the system."""
    
    FACTUAL = auto()      # Verified facts
    PROCEDURAL = auto()   # How to do something
    CONCEPTUAL = auto()   # Understanding of concepts
    HEURISTIC = auto()    # Rules of thumb
    EXPERIENTIAL = auto() # Learned from experience
    META = auto()         # Knowledge about knowledge
    
class TypedKnowledgeEntry(KnowledgeEntry):
    """Knowledge entry with explicit type information."""
    
    knowledge_type: KnowledgeType
    related_entries: List[UUID] = Field(default_factory=list)
    contradicts: List[UUID] = Field(default_factory=list)
    
    def merge_with(self, other: "TypedKnowledgeEntry") -> "TypedKnowledgeEntry":
        """Merge with another knowledge entry if compatible."""
        if self.knowledge_type != other.knowledge_type:
            raise ValueError("Cannot merge different knowledge types")
            
        # Implement merging logic based on knowledge type
              ]]>
            </example>
          </knowledge_types>
        </knowledge_representation>

        <learning_mechanisms>
          <incremental_learning>
            <rule>Implement gradual knowledge refinement</rule>
            <rule>Track confidence over time</rule>
            <rule>Support revision of existing knowledge</rule>
            <example>
              <![CDATA[
from typing import Dict, Any, List, Optional, Tuple
import numpy as np

class IncrementalLearner:
    """Component that gradually refines knowledge over time."""
    
    def __init__(
        self,
        initial_knowledge: Optional[Dict[str, TypedKnowledgeEntry]] = None,
        learning_rate: float = 0.1
    ):
        self.knowledge = initial_knowledge or {}
        self.learning_rate = learning_rate
        self.history = []
        
    def learn_from_observation(
        self,
        observation: Dict[str, Any],
        knowledge_type: KnowledgeType,
        source: str,
        confidence: float = 0.7
    ) -> UUID:
        """Learn from a new observation.
        
        Args:
            observation: New information to incorporate
            knowledge_type: Type of knowledge being added
            source: Where this observation came from
            confidence: Initial confidence in this observation
            
        Returns:
            ID of the created or updated knowledge entry
        """
        # Check if this observation relates to existing knowledge
        existing_entry = self._find_related_entry(observation, knowledge_type)
        
        if existing_entry:
            return self._update_existing_knowledge(
                existing_entry, observation, confidence
            )
        else:
            return self._create_new_knowledge(
                observation, knowledge_type, source, confidence
            )
            
    def _find_related_entry(
        self,
        observation: Dict[str, Any],
        knowledge_type: KnowledgeType
    ) -> Optional[TypedKnowledgeEntry]:
        """Find existing knowledge that relates to the observation."""
        # Implementation of semantic matching
        pass
        
    def _update_existing_knowledge(
        self,
        entry: TypedKnowledgeEntry,
        observation: Dict[str, Any],
        new_confidence: float
    ) -> UUID:
        """Update existing knowledge with new observation."""
        # Record history before update
        self.history.append({
            "entry_id": entry.id,
            "previous_state": entry.copy(),
            "timestamp": datetime.now()
        })
        
        # Update confidence using exponential moving average
        entry.confidence = (
            (1 - self.learning_rate) * entry.confidence +
            self.learning_rate * new_confidence
        )
        
        # Update content based on knowledge type
        if entry.knowledge_type == KnowledgeType.FACTUAL:
            # For factual knowledge, replace with higher confidence
            if new_confidence > entry.confidence:
                entry.content.update(observation)
        elif entry.knowledge_type == KnowledgeType.EXPERIENTIAL:
            # For experiential, accumulate observations
            for key, value in observation.items():
                if key in entry.content:
                    if isinstance(entry.content[key], list):
                        entry.content[key].append(value)
                    else:
                        entry.content[key] = [entry.content[key], value]
                else:
                    entry.content[key] = value
                    
        entry.update_access_stats()
        return entry.id
              ]]>
            </example>
          </incremental_learning>

          <capability_management>
            <rule>Design capabilities as composable modules</rule>
            <rule>Support dynamic capability discovery</rule>
            <rule>Implement capability prerequisites</rule>
            <example>
              <![CDATA[
from typing import Dict, Set, Type, ClassVar, List
from pepperpy.core.base import BaseCapability

class CapabilityRegistry:
    """Registry for agent capabilities."""
    
    _capabilities: ClassVar[Dict[str, Type[BaseCapability]]] = {}
    _dependencies: ClassVar[Dict[str, Set[str]]] = {}
    
    @classmethod
    def register(
        cls,
        capability_cls: Type[BaseCapability],
        dependencies: List[str] = None
    ) -> None:
        """Register a capability with its dependencies.
        
        Args:
            capability_cls: The capability class to register
            dependencies: Other capabilities this one depends on
        """
        name = capability_cls.__name__
        cls._capabilities[name] = capability_cls
        cls._dependencies[name] = set(dependencies or [])
        
    @classmethod
    def get_capability(cls, name: str) -> Type[BaseCapability]:
        """Get a capability by name."""
        if name not in cls._capabilities:
            raise ValueError(f"Capability {name} not registered")
        return cls._capabilities[name]
        
    @classmethod
    def resolve_dependencies(cls, names: List[str]) -> List[str]:
        """Resolve dependencies for a list of capabilities.
        
        Returns a topologically sorted list of capabilities
        that includes all dependencies.
        """
        # Implementation of topological sort
        pass
              ]]>
            </example>
          </capability_management>
        </learning_mechanisms>

        <integration_patterns>
          <agent_learning>
            <rule>Implement experience-based learning</rule>
            <rule>Support feedback incorporation</rule>
            <rule>Design for multi-session knowledge retention</rule>
            <example>
              <![CDATA[
from typing import Dict, Any, List, Optional
from pepperpy.agents.base import BaseAgent
from pepperpy.llm.providers import BaseLLMProvider

class LearningAgent(BaseAgent):
    """Agent that learns from its experiences."""
    
    def __init__(
        self,
        name: str,
        llm_provider: BaseLLMProvider,
        knowledge_base: Optional[IncrementalLearner] = None,
        capabilities: List[str] = None
    ):
        super().__init__(name=name, llm_provider=llm_provider)
        self.knowledge = knowledge_base or IncrementalLearner()
        self.capabilities = self._initialize_capabilities(capabilities or [])
        self.session_memory = []
        
    async def learn_from_interaction(
        self,
        interaction: Dict[str, Any],
        outcome: Dict[str, Any],
        feedback: Optional[Dict[str, Any]] = None
    ) -> None:
        """Learn from an interaction.
        
        Args:
            interaction: The interaction details
            outcome: The result of the interaction
            feedback: Optional feedback on the interaction
        """
        # Extract knowledge from the interaction
        knowledge = self._extract_knowledge(interaction, outcome, feedback)
        
        # Store in session memory
        self.session_memory.append({
            "interaction": interaction,
            "outcome": outcome,
            "feedback": feedback,
            "timestamp": datetime.now()
        })
        
        # Learn from the extracted knowledge
        for item in knowledge:
            self.knowledge.learn_from_observation(
                observation=item["content"],
                knowledge_type=item["type"],
                source=item["source"],
                confidence=item["confidence"]
            )
            
    def _extract_knowledge(
        self,
        interaction: Dict[str, Any],
        outcome: Dict[str, Any],
        feedback: Optional[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """Extract knowledge from an interaction.
        
        This uses the agent's capabilities to analyze the interaction
        and identify valuable knowledge to retain.
        """
        # Implementation of knowledge extraction
        pass
              ]]>
            </example>
          </agent_learning>
        </integration_patterns>
      </guidelines>
    </action>
  </actions>

  <examples>
    <example>
      <correct>
        <description>Well-structured AI learning component</description>
        <content>
          <![CDATA[
from typing import Dict, Any, List, Optional, Union
from datetime import datetime
from uuid import uuid4
from pydantic import BaseModel, Field

from pepperpy.core.base import BaseComponent
from pepperpy.capabilities.base import LearningCapability
from pepperpy.agents.memory import MemoryProvider

class KnowledgeEntry(BaseModel):
    """Represents a unit of knowledge with metadata.
    
    Knowledge entries include both the content and metadata about
    the knowledge, such as sources, confidence, and access patterns.
    """
    
    id: str = Field(default_factory=lambda: str(uuid4()))
    content: Dict[str, Any]
    source: str
    source_type: str
    confidence: float = Field(ge=0.0, le=1.0)
    created_at: datetime = Field(default_factory=datetime.now)
    last_accessed: Optional[datetime] = None
    access_count: int = 0
    tags: List[str] = Field(default_factory=list)
    
    class Config:
        schema_extra = {
            "example": {
                "id": "f8d7e91c-3f4b-4e6a-9d2c-8f7b1a3b9c0d",
                "content": {
                    "concept": "Neural Networks",
                    "definition": "Computational systems inspired by biological neural networks"
                },
                "source": "Introduction to Machine Learning, Chapter 5",
                "source_type": "textbook",
                "confidence": 0.95,
                "tags": ["machine_learning", "neural_networks", "definition"]
            }
        }

class AdaptiveLearning(BaseComponent, LearningCapability):
    """Component that adapts and learns from experiences.
    
    This component implements incremental learning that 
    allows the system to gradually refine its knowledge
    and adapt to new information.
    """
    
    def __init__(
        self,
        memory_provider: MemoryProvider,
        learning_rate: float = 0.1,
        confidence_threshold: float = 0.3
    ):
        """Initialize the adaptive learning component.
        
        Args:
            memory_provider: Provider for storing and retrieving memory
            learning_rate: Rate at which new knowledge affects existing knowledge
            confidence_threshold: Minimum confidence to retain knowledge
        """
        super().__init__()
        self.memory = memory_provider
        self.learning_rate = learning_rate
        self.confidence_threshold = confidence_threshold
        self.logger.info("Adaptive learning component initialized")
        
    async def learn_from_experience(
        self,
        experience: Dict[str, Any],
        source: str,
        tags: Optional[List[str]] = None
    ) -> str:
        """Learn from a new experience.
        
        Args:
            experience: The experience to learn from
            source: Where this experience came from
            tags: Optional tags to categorize this knowledge
            
        Returns:
            ID of the created or updated knowledge entry
        """
        self.logger.debug(f"Learning from experience: {source}")
        
        # Extract knowledge from experience
        knowledge = self._extract_knowledge(experience)
        
        # Check for related existing knowledge
        existing = await self._find_related_knowledge(knowledge, tags)
        
        if existing:
            # Update existing knowledge
            entry_id = await self._update_knowledge(existing, knowledge)
            self.logger.info(f"Updated existing knowledge: {entry_id}")
        else:
            # Create new knowledge entry
            entry = KnowledgeEntry(
                content=knowledge,
                source=source,
                source_type=self._determine_source_type(source),
                confidence=self._calculate_initial_confidence(knowledge),
                tags=tags or []
            )
            
            entry_id = entry.id
            await self.memory.store("knowledge", entry_id, entry.dict())
            self.logger.info(f"Created new knowledge entry: {entry_id}")
            
        return entry_id
        
    async def retrieve_relevant_knowledge(
        self,
        context: Dict[str, Any],
        max_items: int = 5
    ) -> List[KnowledgeEntry]:
        """Retrieve knowledge relevant to the given context.
        
        Args:
            context: The context to find relevant knowledge for
            max_items: Maximum number of knowledge items to return
            
        Returns:
            List of relevant knowledge entries
        """
        # Implementation of knowledge retrieval
        pass
          ]]>
        </content>
      </correct>
      <incorrect>
        <description>Poorly structured learning implementation</description>
        <content>
          <![CDATA[
class SimpleMemory:
    def __init__(self):
        self.knowledge = {}
    
    def remember(self, key, value):
        # Missing type hints
        # No metadata
        # No versioning or confidence
        self.knowledge[key] = value
    
    def recall(self, key):
        # No fuzzy matching
        # No relevance sorting
        return self.knowledge.get(key)
          ]]>
        </content>
      </incorrect>
    </example>
  </examples>
</rule>