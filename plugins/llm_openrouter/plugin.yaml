# OpenRouter Provider Plugin Metadata
name: "OpenRouter LLM Provider"
version: "0.1.0"
description: "Provider for OpenRouter API, supporting various LLM models"
author: "PepperPy Team"
plugin_category: "llm"
provider_type: "openrouter"
required_config_keys:
  - "api_key"

# Default configuration values
default_config:
  model: "openai/gpt-3.5-turbo"
  base_url: "https://openrouter.ai/api/v1"
  temperature: 0.7
  max_tokens: 1024

# Configuration schema
config_schema:
  api_key:
    description: "OpenRouter API key"
    required: true
    env_var: "OPENROUTER_API_KEY"
    type: "string"
    secret: true
  
  model:
    description: "Model to use, e.g. openai/gpt-3.5-turbo, anthropic/claude-3-opus"
    required: false
    default: "openai/gpt-3.5-turbo"
    type: "string"
  
  base_url:
    description: "OpenRouter API base URL"
    required: false
    default: "https://openrouter.ai/api/v1"
    type: "string"
  
  temperature:
    description: "Sampling temperature between 0.0 (deterministic) and 2.0 (creative)"
    required: false
    default: 0.7
    type: "float"
    min: 0.0
    max: 2.0
  
  max_tokens:
    description: "Maximum tokens to generate in the response"
    required: false
    default: 1024
    type: "integer"
    min: 1

# Documentation
documentation:
  usage: |
    OpenRouter provider for language model tasks.
    
    Requires an OpenRouter API key which can be specified:
    1. As a constructor parameter: api_key="key-..."
    2. As an environment variable: OPENROUTER_API_KEY or PEPPERPY_LLM__OPENROUTER__API_KEY
    
    Example usage:
    ```python
    from pepperpy import create_provider
    
    provider = create_provider("llm", "openrouter", api_key="your-api-key")
    
    response = await provider.generate("Tell me a joke.")
    print(response.content)
    ```
  
  models:
    - "anthropic/claude-3-opus"
    - "anthropic/claude-3-sonnet"
    - "anthropic/claude-2"
    - "openai/gpt-4"
    - "openai/gpt-3.5-turbo"
    - "google/palm-2"
    - "meta/llama-2-70b-chat"
    - "meta/llama-2-13b-chat"
    - "meta/llama-2-7b-chat" 