"""OpenRouter provider for LLM tasks.

This module provides the OpenRouter provider implementation for LLM tasks,
supporting various models through OpenRouter's API.
"""

import json
from collections.abc import AsyncIterator
from typing import Any, Dict, List, Optional, Union

import httpx

from pepperpy.llm import (
    GenerationChunk,
    GenerationResult,
    LLMProvider,
    Message,
    MessageRole,
)
from pepperpy.plugin import ProviderPlugin


class OpenRouterProvider(LLMProvider, ProviderPlugin):
    """OpenRouter provider for LLM tasks."""

    # Attributes auto-bound from plugin.yaml
    api_key: str
    model: str
    base_url: str
    temperature: float
    max_tokens: int
    client: Optional[httpx.AsyncClient] = None

    def __init__(self, **kwargs: Any) -> None:
        """Initialize the OpenRouter provider."""
        super().__init__(**kwargs)
        self.client = None

    async def initialize(self) -> None:
        """Initialize the OpenRouter client."""
        # Initialize client with auto-bound api_key
        self.client = httpx.AsyncClient(
            base_url=self.base_url,
            headers={
                "Authorization": f"Bearer {self.api_key}",
                "HTTP-Referer": "https://github.com/pimentel/pepperpy",
                "X-Title": "PepperPy Framework",
            },
        )

    def _convert_messages(
        self, messages: Union[str, List[Message]]
    ) -> List[Dict[str, Any]]:
        """Convert PepperPy messages to OpenRouter format."""
        # Handle single string as user message
        if isinstance(messages, str):
            return [{"role": "user", "content": messages}]

        # Convert list of Message objects
        openrouter_messages = []
        for msg in messages:
            message_dict = {
                "role": msg.role.value,
                "content": msg.content,
            }
            if msg.name:
                message_dict["name"] = msg.name

            openrouter_messages.append(message_dict)

        return openrouter_messages

    async def generate(
        self,
        messages: Union[str, List[Message]],
        **kwargs: Any,
    ) -> GenerationResult:
        """Generate text using the OpenRouter API."""
        # Convert messages to OpenRouter format
        openrouter_messages = self._convert_messages(messages)

        # Use auto-bound attributes with kwargs overrides
        temperature = kwargs.get("temperature", self.temperature)
        max_tokens = kwargs.get("max_tokens", self.max_tokens)
        model = kwargs.get("model", self.model)

        # Make API call
        if not self.client:
            await self.initialize()
            assert self.client is not None

        response = await self.client.post(
            "/chat/completions",
            json={
                "model": model,
                "messages": openrouter_messages,
                "temperature": temperature,
                "max_tokens": max_tokens,
            },
        )

        # Handle errors
        response.raise_for_status()
        completion = response.json()

        if not completion.get("choices"):
            raise ValueError("No content generated by OpenRouter")

        content = completion["choices"][0]["message"]["content"] or ""

        # Build result
        if isinstance(messages, str):
            messages_list = [Message(role=MessageRole.USER, content=messages)]
        else:
            messages_list = messages.copy()

        # Add response to messages
        messages_list.append(Message(role=MessageRole.ASSISTANT, content=content))

        # Extract usage statistics
        usage = completion.get("usage")

        return GenerationResult(
            content=content,
            messages=messages_list,
            usage=usage,
            metadata={
                "model": completion.get("model"),
                "created": completion.get("created"),
                "id": completion.get("id"),
            },
        )

    async def generate_stream(
        self,
        messages: Union[str, List[Message]],
        **kwargs: Any,
    ) -> AsyncIterator[GenerationChunk]:
        """Generate text in streaming mode using the OpenRouter API."""
        # Convert messages to OpenRouter format
        openrouter_messages = self._convert_messages(messages)

        # Use auto-bound attributes with kwargs overrides
        temperature = kwargs.get("temperature", self.temperature)
        max_tokens = kwargs.get("max_tokens", self.max_tokens)
        model = kwargs.get("model", self.model)

        # Make API call with streaming
        if not self.client:
            await self.initialize()
            assert self.client is not None

        response = await self.client.post(
            "/chat/completions",
            json={
                "model": model,
                "messages": openrouter_messages,
                "temperature": temperature,
                "max_tokens": max_tokens,
                "stream": True,
            },
            timeout=60.0,  # Extended timeout for streaming
        )

        # Handle errors
        response.raise_for_status()

        # Process the streaming response
        async for line in response.aiter_lines():
            line = line.strip()

            # Skip empty lines or non-data lines
            if not line or line == "data: [DONE]":
                continue

            if line.startswith("data: "):
                data = line[6:]  # Remove "data: " prefix
                try:
                    chunk = json.loads(data)

                    if not chunk.get("choices"):
                        continue

                    delta = chunk["choices"][0].get("delta", {})
                    content = delta.get("content", "")

                    if content:
                        yield GenerationChunk(
                            content=content,
                            finish_reason=chunk["choices"][0].get("finish_reason"),
                            metadata={"model": model},
                        )
                except Exception:
                    # Skip invalid chunks
                    continue

    async def cleanup(self) -> None:
        """Clean up provider resources."""
        if self.client:
            await self.client.aclose()
            self.client = None
