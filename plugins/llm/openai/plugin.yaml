# Plugin metadata
type: llm
provider: openai
entry_point: OpenAIProvider
description: OpenAI LLM provider for PepperPy
version: 0.2.0
author: PepperPy Team
license: MIT

# Models provided by this plugin
models:
  - gpt-4o
  - gpt-4-turbo
  - gpt-4
  - gpt-3.5-turbo

# Configuration schema
config_schema:
  type: object
  required:
    - api_key
  properties:
    api_key:
      type: string
      description: OpenAI API key
    model:
      type: string
      description: OpenAI model to use
      default: gpt-4-turbo
    temperature:
      type: number
      description: Sampling temperature (0-1)
      default: 0.7
    max_tokens:
      type: integer
      description: Maximum number of tokens to generate
      default: 1024
    top_p:
      type: number
      description: Nucleus sampling parameter (0-1)
      default: 1.0
    presence_penalty:
      type: number
      description: Presence penalty (-2.0 to 2.0)
      default: 0.0
    frequency_penalty:
      type: number
      description: Frequency penalty (-2.0 to 2.0)
      default: 0.0

# Default configuration
default_config:
  model: gpt-4-turbo
  temperature: 0.7
  max_tokens: 1024
  top_p: 1.0
  presence_penalty: 0.0
  frequency_penalty: 0.0

# Documentation
documentation: |
  # OpenAI LLM Provider

  This plugin provides access to OpenAI's language models.

  ## Configuration

  - `api_key`: OpenAI API key (required)
  - `model`: Model to use (default: gpt-4-turbo)
  - `temperature`: Sampling temperature (default: 0.7)
  - `max_tokens`: Maximum tokens to generate (default: 1024)
  - `top_p`: Top p sampling parameter (default: 1.0)
  - `presence_penalty`: Presence penalty (default: 0.0)
  - `frequency_penalty`: Frequency penalty (default: 0.0)

  ## Available Models

  - gpt-4o
  - gpt-4-turbo
  - gpt-4
  - gpt-3.5-turbo

  ## Usage

  ```python
  from pepperpy import PepperPy

  # Create PepperPy instance with OpenAI
  pepper = PepperPy()
  pepper.with_plugin(
      "llm",
      "openai",
      api_key="your-api-key",
      model="gpt-4-turbo"
  )

  # Use the LLM
  response = await pepper.ask_query("What is artificial intelligence?")
  print(response)
  ```

# Metadata
metadata:
  provider_url: https://openai.com/
  requires_api_key: true

dependencies:
  - openai>=1.0.0
