name: llm/openai
version: 0.1.0
description: Provider for the OpenAI GPT models
author: PepperPy Team
required_config_keys:
- api_key
default_config:
  model: gpt-3.5-turbo
  temperature: 0.7
  max_tokens: 1024
config_schema:
  api_key:
    description: OpenAI API key
    required: true
    env_var: PEPPERPY_LLM__OPENAI_API_KEY
    type: string
  model:
    description: Model to use, e.g. gpt-3.5-turbo, gpt-4
    required: false
    default: gpt-3.5-turbo
    type: string
  temperature:
    description: Sampling temperature between 0.0 (deterministic) and 2.0 (creative)
    required: false
    default: 0.7
    type: float
    min: 0.0
    max: 2.0
  max_tokens:
    description: Maximum tokens to generate in the response
    required: false
    default: 1024
    type: integer
    min: 1
documentation:
  usage: 'OpenAI provider for language model tasks.


    Requires an OpenAI API key which can be specified:

    1. As a constructor parameter: api_key="sk-..."

    2. As an environment variable: PEPPERPY_LLM__OPENAI_API_KEY (recomendado) ou OPENAI_API_KEY
    (compatibilidade)


    Example usage:

    ```python

    from pepperpy import create_provider


    provider = create_provider("llm", "openai", api_key="your-api-key")


    response = await provider.generate("Tell me a joke.")

    print(response.content)

    ```

    '
  parameters:
    api_key:
      description: OpenAI API key
      required: true
      env_var: PEPPERPY_LLM__OPENAI_API_KEY
    model:
      description: Model to use, e.g. gpt-3.5-turbo, gpt-4
      required: false
      default: gpt-3.5-turbo
    temperature:
      description: Sampling temperature between 0.0 (deterministic) and 2.0 (creative)
      required: false
      default: 0.7
    max_tokens:
      description: Maximum tokens to generate in the response
      required: false
      default: 1024
category: llm
provider_name: openai
entry_point: provider.OpenAIProvider
pepperpy_compatibility: '>=0.1.0'
