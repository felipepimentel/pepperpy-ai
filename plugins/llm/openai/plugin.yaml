type: llm
provider: openai
module: pepperpy.plugins.llm.openai.provider
class: OpenAIProvider
description: OpenAI LLM provider for PepperPy
version: 0.1.0
author: PepperPy Team
license: MIT
config:
  api_key:
    description: OpenAI API key
    required: true
    env_var: PEPPERPY_LLM__OPENAI_API_KEY
    type: string
  model:
    description: Model to use for generation
    required: false
    default: gpt-3.5-turbo
    type: string
  temperature:
    description: Sampling temperature between 0.0 (deterministic) and 2.0 (creative)
    required: false
    default: 0.7
    type: float
    min: 0.0
    max: 2.0
  max_tokens:
    description: Maximum tokens to generate in the response
    required: false
    default: 1024
    type: integer
    min: 1
documentation: |
  # OpenAI LLM Provider

  This plugin provides access to OpenAI's GPT models through their API.

  ## Configuration

  - `api_key`: OpenAI API key (required)
  - `model`: Model to use (default: gpt-3.5-turbo)
  - `temperature`: Sampling temperature (default: 0.7)
  - `max_tokens`: Maximum tokens to generate (default: 1024)

  ## Available Models

  - gpt-4-turbo (recommended for complex tasks)
  - gpt-4
  - gpt-3.5-turbo (default)
  - gpt-3.5-turbo-16k

  Note: You can also use environment variables for configuration:
  - `PEPPERPY_LLM__OPENAI_API_KEY` (recommended)
  - `OPENAI_API_KEY` (for compatibility)
pepperpy_compatibility: '>=0.1.0'
