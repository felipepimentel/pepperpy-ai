name: llm/openai
version: 0.1.0
description: OpenAI provider for LLM
author: PepperPy Team
plugin_type: llm
category: provider
provider_name: openai
entry_point: provider.OpenAIProvider

# Configuration schema
config_schema:
  type: object
  properties:
    api_key:
      type: string
      description: OpenAI API key
    model:
      type: string
      description: Model to use
      default: gpt-3.5-turbo
    temperature:
      type: number
      description: Temperature for sampling
      default: 0.7
    max_tokens:
      type: integer
      description: Maximum number of tokens
      default: 1000

# Examples for testing
examples:
  - name: "simple_completion"
    description: "Basic text completion"
    input:
      prompt: "Hello, how are you?"
      max_tokens: 50
    expected_output:
      status: "success"
      
  - name: "chat_completion"
    description: "Chat completion with system message"
    input:
      messages:
        - role: "system"
          content: "You are a helpful assistant."
        - role: "user"
          content: "What is the capital of France?"
    expected_output:
      status: "success"
      
  - name: "streaming_completion"
    description: "Streaming completion"
    input:
      prompt: "List 5 capital cities"
      stream: true
    expected_output:
      status: "success" 