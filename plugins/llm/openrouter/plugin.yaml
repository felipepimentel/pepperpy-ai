name: llm/openrouter
version: 0.1.0
description: Provider for OpenRouter API, supporting various LLM models
author: PepperPy Team
required_config_keys:
- api_key
default_config:
  model: openai/gpt-3.5-turbo
  base_url: https://openrouter.ai/api/v1
  temperature: 0.7
  max_tokens: 1024
config_schema:
  api_key:
    description: OpenRouter API key
    required: true
    env_var: PEPPERPY_LLM__OPENROUTER_API_KEY
    type: string
    secret: true
  model:
    description: Model to use, e.g. openai/gpt-3.5-turbo, anthropic/claude-3-opus
    required: false
    default: openai/gpt-3.5-turbo
    type: string
  base_url:
    description: OpenRouter API base URL
    required: false
    default: https://openrouter.ai/api/v1
    type: string
  temperature:
    description: Sampling temperature between 0.0 (deterministic) and 2.0 (creative)
    required: false
    default: 0.7
    type: float
    min: 0.0
    max: 2.0
  max_tokens:
    description: Maximum tokens to generate in the response
    required: false
    default: 1024
    type: integer
    min: 1
documentation:
  usage: 'OpenRouter provider for language model tasks.


    Requires an OpenRouter API key which can be specified:

    1. As a constructor parameter: api_key="key-..."

    2. As an environment variable: PEPPERPY_LLM__OPENROUTER_API_KEY (recomendado)
    ou OPENROUTER_API_KEY (compatibilidade)


    Example usage:

    ```python

    from pepperpy import create_provider


    provider = create_provider("llm", "openrouter", api_key="your-api-key")


    response = await provider.generate("Tell me a joke.")

    print(response.content)

    ```

    '
  models:
  - anthropic/claude-3-opus
  - anthropic/claude-3-sonnet
  - anthropic/claude-2
  - openai/gpt-4
  - openai/gpt-3.5-turbo
  - google/palm-2
  - meta/llama-2-70b-chat
  - meta/llama-2-13b-chat
  - meta/llama-2-7b-chat
category: llm
provider_name: openrouter
entry_point: provider.OpenRouterProvider
pepperpy_compatibility: '>=0.1.0'
