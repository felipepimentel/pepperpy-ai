name: workflow/llm_completion
version: 0.1.0
description: Simple workflow for LLM completions and text generation
author: PepperPy Team
license: MIT
type: workflow
config_schema:
  provider:
    type: string
    description: LLM provider to use (e.g., openai, anthropic, llama)
    default: openai
  model:
    type: string
    description: LLM model to use
    default: gpt-3.5-turbo
  api_key:
    type: string
    description: API key for the LLM provider
  temperature:
    type: number
    description: Temperature for text generation (0.0 to 1.0)
    default: 0.7
    minimum: 0.0
    maximum: 1.0
  max_tokens:
    type: integer
    description: Maximum number of tokens to generate
    default: 1024
  system_prompt:
    type: string
    description: System prompt to use for completions
    default: You are a helpful assistant powered by the PepperPy framework.
  output_dir:
    type: string
    description: Directory to save results
    default: ./output/llm
documentation:
  description: 'LLM Completion Workflow provides a simple interface for generating
    text using

    Large Language Models, supporting:


    1. Text completion with various prompts

    2. Content generation with custom system instructions

    3. Completion with basic formatting options


    This workflow makes it easy to generate text with various LLM providers through

    a consistent interface, while keeping the API simple and focused.

    '
  features:
  - Text Completion: Generate completions with various models
  - Content Generation: Create various types of content with different instructions
  - Format Control: Control output format with system instructions
  usage_examples:
  - title: Basic Text Completion
    python: "from pepperpy.workflow import create_provider\n\n# Create the LLM completion\
      \ workflow provider\nworkflow = create_provider(\"llm_completion\", \n     \
      \                     provider=\"openai\",\n                          model=\"\
      gpt-4\",\n                          api_key=\"your_api_key\")\n\n# Generate\
      \ a completion\nresult = await workflow.execute({\n    \"task\": \"complete\"\
      ,\n    \"input\": {\n        \"prompt\": \"Explain what PepperPy is in one paragraph.\"\
      \n    }\n})\n\n# Print the completion\nprint(result[\"text\"])\n"
  - title: Content Generation
    python: "# Create workflow with custom system prompt\nworkflow = create_provider(\"\
      llm_completion\", \n                          provider=\"openai\",\n       \
      \                   model=\"gpt-3.5-turbo\",\n                          system_prompt=\"\
      You are a creative writer who specializes in short stories.\")\n\n# Generate\
      \ a short story\nresult = await workflow.execute({\n    \"task\": \"complete\"\
      ,\n    \"input\": {\n        \"prompt\": \"Write a short story about a robot\
      \ learning to cook.\"\n    }\n})\n\n# Print the story\nprint(result[\"text\"\
      ])\n"
  - title: Generating with CLI
    shell: "# Run LLM completion workflow via CLI\npython -m pepperpy.cli workflow\
      \ run workflow/llm_completion \\\n  --params \"provider=openai\" \\\n  --params\
      \ \"model=gpt-4\" \\\n  --params \"task=complete\" \\\n  --params \"prompt=What\
      \ is the capital of France?\"\n"
requirements:
- pydantic>=2.0.0
- jsonschema>=4.0.0
plugin_type: workflow
provider_name: llm_completion
entry_point: workflow.LLMCompletionWorkflow
