name: workflow_mcp_demo
version: 0.1.0
description: Demonstration workflow that runs an MCP server and client together
author: PepperPy Team
plugin_type: workflow
category: mcp
provider_name: mcp_demo
entry_point: workflow.MCPDemoWorkflow

config_schema:
  type: object
  properties:
    host:
      type: string
      description: Host address for the MCP server
      default: "0.0.0.0"
    port:
      type: integer
      description: Port for the MCP server
      default: 8000
    provider_type:
      type: string
      description: Type of MCP provider to use
      default: "http"
    llm_provider:
      type: string
      description: LLM provider to use for chat
      default: "openai"
    llm_model:
      type: string
      description: LLM model to use
      default: "gpt-3.5-turbo"
    demo_duration:
      type: integer
      description: Duration in seconds to run the demo for
      default: 60

default_config:
  host: "0.0.0.0"
  port: 8000
  provider_type: "http"
  llm_provider: "openai"
  llm_model: "gpt-3.5-turbo"
  demo_duration: 60

documentation:
  description: |
    This workflow demonstrates the integration of MCP server and client components.
    It sets up an MCP server with registered tools, then runs a client that connects
    to the server and uses the tools.
  
  examples:
    - title: Basic usage
      description: Run the MCP demo with default settings
      code: |
        pepperpy run workflow mcp_demo
    
    - title: Custom configuration
      description: Run the MCP demo with custom settings
      code: |
        pepperpy run workflow mcp_demo --config '{"port": 9000, "llm_model": "gpt-4"}'
    
    - title: Custom duration
      description: Run the MCP demo for a specific duration
      code: |
        pepperpy run workflow mcp_demo --config '{"demo_duration": 120}'
  
  notes: |
    # MCP Demo Workflow
    
    This workflow demonstrates the complete integration of Model Context Protocol (MCP) server and client.
    
    ## Features
    
    - Start an MCP server with the specified configuration
    - Register demo tools (calculate, weather, translate)
    - Simulates client requests to demonstrate usage patterns
    
    ## Usage
    
    Run the workflow with:
    
    ```bash
    # Basic usage
    python -m pepperpy.cli workflow run workflow/mcp_demo
    
    # With OpenAI API key
    OPENAI_API_KEY=your_key_here python -m pepperpy.cli workflow run workflow/mcp_demo
    ```
    
    ## CLI Tool
    
    A command-line interface is also provided for interacting with a running MCP server:
    
    ```bash
    # Connect to the local MCP server
    python plugins/workflow/mcp_demo/cli.py
    
    # Connect to a remote server
    python plugins/workflow/mcp_demo/cli.py --host api.example.com --port 443
    ```
    
    The CLI tool provides these commands:
    
    - `/help` - Show help information
    - `/quit` or `/exit` - Exit the CLI
    - `/clear` - Clear conversation history
    - `/models` - List available models
    - `/calc <expression>` - Use the calculate tool
    - `/weather <location>` - Use the weather tool
    - `/translate <text> to <language>` - Use the translate tool
    
    ## Configuration
    
    You can customize the workflow with these parameters:
    
    ```yaml
    host: "0.0.0.0"          # Host address to bind the server to
    port: 8000               # Port for the MCP server
    provider_type: "http"    # Type of MCP provider to use
    llm_provider: "openai"   # LLM provider to use
    llm_model: "gpt-3.5-turbo" # LLM model to use
    demo_duration: 60        # Duration in seconds to run the demo
    ```
    
    ## Demo Tools
    
    The workflow demonstrates these MCP tool integrations:
    
    - **Chat**: Basic conversation with LLM model
    - **Calculate**: Evaluate mathematical expressions (format: `calculate: 2 + 2`)
    - **Weather**: Get weather information for a location (format: `get_weather: London`)
    - **Translate**: Translate text to another language (format: `translate: Hello world to es`) 