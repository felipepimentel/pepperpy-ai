name: workflow/knowledge_management
version: 0.1.0
author: PepperPy Team
description: Knowledge management and RAG workflows for document processing, embedding
  generation, and retrieval-augmented generation.
homepage: https://github.com/pepperpy/pepperpy
repository: https://github.com/pepperpy/pepperpy
config_schema:
  type: object
  properties:
    embedding_model:
      type: string
      description: Embedding model to use for vector embeddings
      default: text-embedding-ada-002
    vector_store:
      type: string
      description: Vector store backend to use
      enum:
      - chroma
      - faiss
      - qdrant
      default: chroma
    chunk_size:
      type: integer
      description: Size of document chunks
      default: 1000
      minimum: 100
      maximum: 8000
    detail_level:
      type: string
      description: Level of detail in responses
      enum:
      - low
      - medium
      - high
      default: medium
    auto_save_results:
      type: boolean
      description: Automatically save results to disk
      default: true
    response_format:
      type: string
      description: Format of response outputs
      enum:
      - text
      - json
      - markdown
      default: text
  required:
  - vector_store
documentation:
  features:
  - Document chunking and preprocessing
  - Vector embedding generation
  - Knowledge base creation and management
  - RAG (Retrieval Augmented Generation)
  - Conversation memory and context management
  description: 'This workflow plugin provides comprehensive knowledge management features:


    - **Document Processing**: Split documents into chunks for efficient processing

    - **Embedding Generation**: Create vector embeddings from text chunks

    - **Knowledge Base Management**: Store and retrieve documents with vector search

    - **RAG Capabilities**: Query knowledge bases to enhance responses with relevant
    information

    - **Conversation Memory**: Maintain conversation history for contextual responses

    '
  usage_examples:
  - title: Create and Query a Knowledge Base
    language: python
    code: "from pepperpy import create_workflow\n\n# Create a knowledge management\
      \ workflow\nworkflow = create_workflow(\"knowledge_management\", \n        \
      \                  vector_store=\"chroma\",\n                          embedding_model=\"\
      text-embedding-ada-002\")\n\n# Sample documents\ndocuments = [\n    \"Retrieval\
      \ Augmented Generation (RAG) is a technique that combines retrieval with generation...\"\
      ,\n    \"Vector databases store and retrieve embeddings efficiently for similarity\
      \ search...\",\n    \"Embeddings represent text as dense vectors in high-dimensional\
      \ space...\"\n]\n\n# Create a knowledge base\nkb_id = await workflow.execute({\n\
      \    \"task\": \"create_kb\",\n    \"input\": {\n        \"name\": \"ai_concepts\"\
      ,\n        \"documents\": documents,\n        \"description\": \"Knowledge base\
      \ about AI concepts\"\n    }\n})[\"kb_id\"]\n\n# Query the knowledge base\n\
      result = await workflow.execute({\n    \"task\": \"query_kb\",\n    \"input\"\
      : {\n        \"kb_id\": kb_id,\n        \"query\": \"How does RAG work?\",\n\
      \        \"detail_level\": \"high\"\n    }\n})\n\nprint(result[\"response\"\
      ])\n"
  - title: Use RAG with Conversation Memory
    language: python
    code: "from pepperpy import create_workflow\n\n# Create a knowledge management\
      \ workflow\nworkflow = create_workflow(\"knowledge_management\")\n\n# Create\
      \ a conversation with memory\nconversation_id = \"user_123\"\n\n# First interaction\n\
      result = await workflow.execute({\n    \"task\": \"memory\",\n    \"input\"\
      : {\n        \"prompt\": \"Tell me about RAG\",\n        \"conversation_id\"\
      : conversation_id\n    }\n})\n\nprint(result[\"response\"])\n\n# Follow-up question\
      \ with RAG\nresult = await workflow.execute({\n    \"task\": \"rag\",\n    \"\
      input\": {\n        \"kb_id\": \"ai_concepts\",\n        \"prompt\": \"How does\
      \ it improve LLM responses?\",\n        \"conversation_id\": conversation_id,\n\
      \        \"history\": result[\"history\"]  # Pass previous history\n    }\n\
      })\n\nprint(result[\"response\"])\n"
requirements:
- chromadb>=0.4.6
- sentence-transformers>=2.2.2
- pydantic>=2.0.0
plugin_type: plugins
provider_name: knowledge_management
entry_point: provider.Knowledge_managementProvider
