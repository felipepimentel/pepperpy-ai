name: ai_gateway
version: 0.1.0
description: AI Gateway workflow provider for multiple LLM integrations
author: PepperPy Team

# Categorization
plugin_type: workflow
category: integration
provider_name: ai_gateway
entry_point: workflow.AIGatewayWorkflow

# Configuration schema
config_schema:
  type: object
  properties:
    provider_type:
      type: string
      description: Type of LLM provider to use (openai, anthropic, etc.)
      default: openai
    model_id:
      type: string
      description: Model identifier for the LLM provider
      default: gpt-3.5-turbo
    temperature:
      type: number
      description: Sampling temperature for response generation
      minimum: 0.0
      maximum: 2.0
      default: 0.7
    max_tokens:
      type: integer
      description: Maximum tokens to generate in response
      minimum: 1
      maximum: 4096
      default: 1000
    use_tools:
      type: boolean
      description: Whether to enable tools/function calling
      default: false
    tools:
      type: array
      description: List of tool names to enable
      items:
        type: string
      default: []

# Default configuration
default_config:
  provider_type: openai
  model_id: gpt-3.5-turbo
  temperature: 0.7
  max_tokens: 1000
  use_tools: false
  tools: []

# Examples for testing
examples:
  - name: "chat_operation"
    description: "Basic chat operation"
    input:
      operation: "chat"
      messages:
        - role: "user"
          content: "Hello, how are you?"
    expected_output:
      status: "success"
  
  - name: "completion_operation"
    description: "Text completion operation"
    input:
      operation: "complete"
      prompt: "Once upon a time"
      max_tokens: 50
    expected_output:
      status: "success"
      
  - name: "tool_usage"
    description: "Using a tool with the gateway"
    input:
      operation: "chat"
      messages:
        - role: "user"
          content: "What is 2+2?"
      use_tools: true
      tools: ["calculator"]
    expected_output:
      status: "success"

# Documentation
documentation:
  description: |
    AI Gateway workflow provides a unified interface to multiple LLM providers
    with consistent API, error handling, and integration features.
    
  usage: |
    The AI Gateway workflow can be used for:
    1. Accessing multiple LLM providers through a consistent interface
    2. Applying middleware like rate limiting, caching, and retry logic
    3. Using tools and function calling capabilities
    4. Combining multiple models in a single workflow
    
  examples:
    - title: Basic Usage
      description: Simple chat request with default provider
      code: |
        from pepperpy import PepperPy
        
        # Initialize with default provider
        pepper = PepperPy().with_workflow("ai_gateway")
        
        # Execute chat request
        response = await pepper.execute_workflow("ai_gateway", {
            "operation": "chat",
            "messages": [{"role": "user", "content": "Hello, how can you help me today?"}]
        })
        
    - title: Custom Configuration
      description: Configure with specific provider
      code: |
        from pepperpy import PepperPy
        
        # Initialize with custom config
        pepper = PepperPy().with_workflow("ai_gateway", config={
            "provider_type": "anthropic",
            "model_id": "claude-2",
            "temperature": 0.5,
            "max_tokens": 2000
        })
        
        # Execute request
        response = await pepper.execute_workflow("ai_gateway", {
            "operation": "chat",
            "messages": [{"role": "user", "content": "Write a short poem about AI"}]
        }) 